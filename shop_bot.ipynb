{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## speak onetime if person is apper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import pyttsx3\n",
    "\n",
    "# Initialize text-to-speech engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Define paths to the model files\n",
    "prototxt_path = r'gender_pre_trained_models\\gender_deploy.prototxt'\n",
    "caffemodel_path = r'gender_pre_trained_models\\gender_net.caffemodel'\n",
    "\n",
    "# Check if files exist\n",
    "if not os.path.isfile(prototxt_path):\n",
    "    raise FileNotFoundError(f\"Cannot find the prototxt file at {prototxt_path}\")\n",
    "if not os.path.isfile(caffemodel_path):\n",
    "    raise FileNotFoundError(f\"Cannot find the caffemodel file at {caffemodel_path}\")\n",
    "\n",
    "# Load the pre-trained Caffe models for gender classification\n",
    "gender_net = cv2.dnn.readNetFromCaffe(prototxt_path, caffemodel_path)\n",
    "\n",
    "# Define the mean values for the gender model\n",
    "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "\n",
    "# Gender list\n",
    "gender_list = ['Male', 'Female']\n",
    "\n",
    "# Load the pre-trained face detection model\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Open the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize variables to keep track of detection and greeting logic\n",
    "last_detect_time = 0\n",
    "last_greet_time = 0\n",
    "greeting_interval = 2  # Interval to check if person is not available\n",
    "greeted = False\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    if len(faces) > 0:\n",
    "        last_detect_time = time.time()\n",
    "        if not greeted:\n",
    "            for (x, y, w, h) in faces:\n",
    "                # Extract the face region\n",
    "                face_img = frame[y:y+h, x:x+w].copy()\n",
    "\n",
    "                # Prepare the face image for classification\n",
    "                blob = cv2.dnn.blobFromImage(face_img, 1.0, (227, 227), MODEL_MEAN_VALUES, swapRB=False)\n",
    "                gender_net.setInput(blob)\n",
    "\n",
    "                # Perform gender classification\n",
    "                gender_preds = gender_net.forward()\n",
    "                gender = gender_list[gender_preds[0].argmax()]\n",
    "\n",
    "                # Draw a rectangle around the face and display the gender\n",
    "                label = f'{gender}'\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "                cv2.putText(frame, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "                # Say the greeting based on detected gender\n",
    "                if gender == 'Male':\n",
    "                    engine.say(\"Hello Sir\")\n",
    "                elif gender == 'Female':\n",
    "                    engine.say(\"Hello Miss\")\n",
    "                engine.runAndWait()\n",
    "                greeted = True\n",
    "    else:\n",
    "        # Check if the person has been missing for more than the greeting interval\n",
    "        if time.time() - last_detect_time >= greeting_interval:\n",
    "            greeted = False\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Gender Classification', frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## good morning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "import datetime\n",
    "import pytz\n",
    "import os\n",
    "import time\n",
    "\n",
    "def get_greeting():\n",
    "    # Define the timezone for Sri Lanka\n",
    "    sri_lanka_tz = pytz.timezone('Asia/Colombo')\n",
    "    \n",
    "    # Get the current time in Sri Lanka\n",
    "    now = datetime.datetime.now(sri_lanka_tz)\n",
    "    \n",
    "    # Determine the greeting based on the current time\n",
    "    hour = now.hour\n",
    "    if 5 <= hour < 12:\n",
    "        return \"Good morning\"\n",
    "    elif 12 <= hour < 18:\n",
    "        return \"Good afternoon\"\n",
    "    else:\n",
    "        return \"Good evening\"\n",
    "\n",
    "def speak(text):\n",
    "    # Convert text to speech\n",
    "    tts = gTTS(text=text, lang='en')\n",
    "    audio_file = 'greeting.mp3'\n",
    "    tts.save(audio_file)\n",
    "    \n",
    "    # Play the audio file\n",
    "    os.system(f\"start {audio_file}\")  # Use \"start\" for Windows, \"open\" for macOS, \"xdg-open\" for Linux\n",
    "\n",
    "def main():\n",
    "    # Define the interval for repeating greetings\n",
    "    greeting_interval = 60 * 60  # 1 hour\n",
    "    last_greeting_time = 0\n",
    "    \n",
    "    while True:\n",
    "        current_time = time.time()\n",
    "        \n",
    "        # Check if it's time to speak a new greeting\n",
    "        if current_time - last_greeting_time >= greeting_interval:\n",
    "            greeting = get_greeting()\n",
    "            speak(greeting)\n",
    "            last_greeting_time = current_time\n",
    "        \n",
    "        # Sleep for a short time to avoid high CPU usage\n",
    "        time.sleep(60)  # Check every minute\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import pyttsx3\n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "# Initialize text-to-speech engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Define paths to the model files\n",
    "prototxt_path = r'gender_pre_trained_models\\gender_deploy.prototxt'\n",
    "caffemodel_path = r'gender_pre_trained_models\\gender_net.caffemodel'\n",
    "\n",
    "# Check if files exist\n",
    "if not os.path.isfile(prototxt_path):\n",
    "    raise FileNotFoundError(f\"Cannot find the prototxt file at {prototxt_path}\")\n",
    "if not os.path.isfile(caffemodel_path):\n",
    "    raise FileNotFoundError(f\"Cannot find the caffemodel file at {caffemodel_path}\")\n",
    "\n",
    "# Load the pre-trained Caffe models for gender classification\n",
    "gender_net = cv2.dnn.readNetFromCaffe(prototxt_path, caffemodel_path)\n",
    "\n",
    "# Define the mean values for the gender model\n",
    "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "\n",
    "# Gender list\n",
    "gender_list = ['Male', 'Female']\n",
    "\n",
    "# Load the pre-trained face detection model\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Open the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize variables to keep track of detection and greeting logic\n",
    "last_detect_time = 0\n",
    "last_greet_time = 0\n",
    "greeting_interval = 2  # Interval to check if person is not available\n",
    "greeted = False\n",
    "\n",
    "def get_time_based_greeting():\n",
    "    # Define the timezone for Sri Lanka\n",
    "    sri_lanka_tz = pytz.timezone('Asia/Colombo')\n",
    "    \n",
    "    # Get the current time in Sri Lanka\n",
    "    now = datetime.datetime.now(sri_lanka_tz)\n",
    "    \n",
    "    # Determine the greeting based on the current time\n",
    "    hour = now.hour\n",
    "    if 5 <= hour < 12:\n",
    "        return \"Good morning\"\n",
    "    elif 12 <= hour < 18:\n",
    "        return \"Good afternoon\"\n",
    "    else:\n",
    "        return \"Good evening\"\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    if len(faces) > 0:\n",
    "        last_detect_time = time.time()\n",
    "        if not greeted:\n",
    "            for (x, y, w, h) in faces:\n",
    "                # Extract the face region\n",
    "                face_img = frame[y:y+h, x:x+w].copy()\n",
    "\n",
    "                # Prepare the face image for classification\n",
    "                blob = cv2.dnn.blobFromImage(face_img, 1.0, (227, 227), MODEL_MEAN_VALUES, swapRB=False)\n",
    "                gender_net.setInput(blob)\n",
    "\n",
    "                # Perform gender classification\n",
    "                gender_preds = gender_net.forward()\n",
    "                gender = gender_list[gender_preds[0].argmax()]\n",
    "\n",
    "                # Draw a rectangle around the face and display the gender\n",
    "                label = f'{gender}'\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "                cv2.putText(frame, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "                # Get the time-based greeting\n",
    "                time_based_greeting = get_time_based_greeting()\n",
    "                \n",
    "                # Say the greeting based on detected gender\n",
    "                if gender == 'Male':\n",
    "                    engine.say(f\"{time_based_greeting} Sir\")\n",
    "                elif gender == 'Female':\n",
    "                    engine.say(f\"{time_based_greeting} Miss\")\n",
    "                engine.runAndWait()\n",
    "                greeted = True\n",
    "    else:\n",
    "        # Check if the person has been missing for more than the greeting interval\n",
    "        if time.time() - last_detect_time >= greeting_interval:\n",
    "            greeted = False\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Gender Classification', frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## updated one | say greeting with sir/miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import pyttsx3\n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "# Initialize text-to-speech engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Define paths to the model files\n",
    "prototxt_path = r'gender_pre_trained_models\\gender_deploy.prototxt'\n",
    "caffemodel_path = r'gender_pre_trained_models\\gender_net.caffemodel'\n",
    "\n",
    "# Check if files exist\n",
    "if not os.path.isfile(prototxt_path):\n",
    "    raise FileNotFoundError(f\"Cannot find the prototxt file at {prototxt_path}\")\n",
    "if not os.path.isfile(caffemodel_path):\n",
    "    raise FileNotFoundError(f\"Cannot find the caffemodel file at {caffemodel_path}\")\n",
    "\n",
    "# Load the pre-trained Caffe models for gender classification\n",
    "gender_net = cv2.dnn.readNetFromCaffe(prototxt_path, caffemodel_path)\n",
    "\n",
    "# Define the mean values for the gender model\n",
    "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "\n",
    "# Gender list\n",
    "gender_list = ['Male', 'Female']\n",
    "\n",
    "# Load the pre-trained face detection model\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Open the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize variables to keep track of detection and greeting logic\n",
    "last_detect_time = 0\n",
    "greeting_interval = 2  # Interval to check if person is not available\n",
    "greeted = False\n",
    "\n",
    "def get_time_based_greeting():\n",
    "    # Define the timezone for Sri Lanka\n",
    "    sri_lanka_tz = pytz.timezone('Asia/Colombo')\n",
    "    \n",
    "    # Get the current time in Sri Lanka\n",
    "    now = datetime.datetime.now(sri_lanka_tz)\n",
    "    \n",
    "    # Determine the greeting based on the current time\n",
    "    hour = now.hour\n",
    "    if 5 <= hour < 12:\n",
    "        return \"Good morning\"\n",
    "    elif 12 <= hour < 18:\n",
    "        return \"Good afternoon\"\n",
    "    else:\n",
    "        return \"Good evening\"\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    if len(faces) > 0:\n",
    "        last_detect_time = time.time()\n",
    "\n",
    "        if not greeted:\n",
    "            for (x, y, w, h) in faces:\n",
    "                # Extract the face region\n",
    "                face_img = frame[y:y+h, x:x+w].copy()\n",
    "\n",
    "                # Prepare the face image for classification\n",
    "                blob = cv2.dnn.blobFromImage(face_img, 1.0, (227, 227), MODEL_MEAN_VALUES, swapRB=False)\n",
    "                gender_net.setInput(blob)\n",
    "\n",
    "                # Perform gender classification\n",
    "                gender_preds = gender_net.forward()\n",
    "                gender = gender_list[gender_preds[0].argmax()]\n",
    "\n",
    "                # Draw a rectangle around the face and display the gender\n",
    "                label = f'{gender}'\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "                cv2.putText(frame, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "                # Get the time-based greeting\n",
    "                time_based_greeting = get_time_based_greeting()\n",
    "                \n",
    "                # Say the greeting based on detected gender\n",
    "                if gender == 'Male':\n",
    "                    engine.say(f\"{time_based_greeting} Sir\")\n",
    "                elif gender == 'Female':\n",
    "                    engine.say(f\"{time_based_greeting} Miss\")\n",
    "                engine.runAndWait()\n",
    "                \n",
    "                # Set greeted to True to prevent repeated greetings\n",
    "                greeted = True\n",
    "                break  # Exit the loop after greeting\n",
    "    else:\n",
    "        # Check if the person has been missing for more than the greeting interval\n",
    "        if time.time() - last_detect_time >= greeting_interval:\n",
    "            greeted = False\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Gender Classification', frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gsheet reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=965765739038-bsu15r84t2433o5ncsj3fnuktd39q13u.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A64558%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fspreadsheets&state=l1DnhPlkqEaPLde5jhafG94uOWsnep&access_type=offline\n",
      "Product: Product, Brand and Type: BrandType, Price: Price\n",
      "Product: TV, Brand and Type: samsung 32'', Price: Rs.38000\n",
      "Product: gas cooker , Brand and Type: usha , Price: Rs.15000\n",
      "Product: New Product, Brand and Type: New Brand, Price: New Price\n",
      "Product: Another Product, Brand and Type: Another Brand, Price: Another Price\n",
      "Cells updated: 6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pyttsx3\n",
    "from google.oauth2 import service_account\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "# Path to your OAuth 2.0 credentials file\n",
    "CREDENTIALS_FILE = 'credentials.json'\n",
    "# Scopes required for Google Sheets API\n",
    "SCOPES = ['https://www.googleapis.com/auth/spreadsheets']\n",
    "\n",
    "def get_google_sheets_service():\n",
    "    \"\"\"Builds a Google Sheets API service object using OAuth 2.0.\"\"\"\n",
    "    flow = InstalledAppFlow.from_client_secrets_file(CREDENTIALS_FILE, SCOPES)\n",
    "    creds = flow.run_local_server(port=0)  # Opens a browser window for user authorization\n",
    "    service = build('sheets', 'v4', credentials=creds)\n",
    "    return service\n",
    "\n",
    "def read_sheet_data(service, spreadsheet_id, range_name):\n",
    "    \"\"\"Reads data from a Google Sheet.\"\"\"\n",
    "    sheet = service.spreadsheets()\n",
    "    result = sheet.values().get(spreadsheetId=spreadsheet_id, range=range_name).execute()\n",
    "    values = result.get('values', [])\n",
    "    if not values:\n",
    "        print('No data found.')\n",
    "    return values\n",
    "\n",
    "def write_sheet_data(service, spreadsheet_id, range_name, values):\n",
    "    \"\"\"Writes data to a Google Sheet.\"\"\"\n",
    "    sheet = service.spreadsheets()\n",
    "    body = {\n",
    "        'values': values\n",
    "    }\n",
    "    result = sheet.values().update(spreadsheetId=spreadsheet_id, range=range_name, valueInputOption='RAW', body=body).execute()\n",
    "    return result\n",
    "\n",
    "def speak(text):\n",
    "    \"\"\"Speaks the provided text.\"\"\"\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "def main():\n",
    "    service = get_google_sheets_service()\n",
    "    \n",
    "    # Replace with your Google Sheets ID and range\n",
    "    spreadsheet_id = '1lNZDwXKNlNkZiLWKksob55RE70e3IbSAhkR0W_pjGV4'\n",
    "    range_name = 'Sheet1!A1:C'  # Adjust the range as needed\n",
    "    \n",
    "    # Read data from the Google Sheet\n",
    "    data = read_sheet_data(service, spreadsheet_id, range_name)\n",
    "    \n",
    "    # Speak the details\n",
    "    for row in data:\n",
    "        if len(row) >= 3:  # Ensure there are at least 3 columns\n",
    "            product = row[0]\n",
    "            brand_type = row[1]\n",
    "            price = row[2]\n",
    "            details = f\"Product: {product}, Brand and Type: {brand_type}, Price: {price}\"\n",
    "            print(details)  # Optional: Print to console\n",
    "            speak(details)  # Read out the details\n",
    "\n",
    "    # Example data to write\n",
    "    new_values = [\n",
    "        [\"New Product\", \"New Brand\", \"New Price\"],\n",
    "        [\"Another Product\", \"Another Brand\", \"Another Price\"]\n",
    "    ]\n",
    "    \n",
    "    # Write new data to the Google Sheet\n",
    "    write_range = 'Sheet1!A4:C'  # Adjust the range where you want to write the new data\n",
    "    result = write_sheet_data(service, spreadsheet_id, write_range, new_values)\n",
    "    print(f\"Cells updated: {result.get('updatedCells')}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## without accesing g account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Product', 'BrandType', 'Price']\n",
      "['TV', \"samsung 32''\", 'Rs.38000']\n",
      "['gas cooker ', 'usha ', 'Rs.15000']\n",
      "['New Product', 'New Brand', 'New Price']\n",
      "['Another Product', 'Another Brand', 'Another Price']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "# Replace with your Google Sheets ID and range\n",
    "SPREADSHEET_ID = '1lNZDwXKNlNkZiLWKksob55RE70e3IbSAhkR0W_pjGV4'  # Extracted from the URL\n",
    "READ_RANGE = 'Sheet1!A1:C'  # Adjust the range as needed\n",
    "\n",
    "# Path to your credentials.json file\n",
    "CREDENTIALS_FILE = 'credentials.json'\n",
    "TOKEN_FILE = 'token.pickle'\n",
    "\n",
    "def get_google_sheets_service():\n",
    "    \"\"\"Builds a Google Sheets API service object.\"\"\"\n",
    "    creds = None\n",
    "\n",
    "    # Load credentials from file if they exist\n",
    "    if os.path.exists(TOKEN_FILE):\n",
    "        with open(TOKEN_FILE, 'rb') as token:\n",
    "            creds = pickle.load(token)\n",
    "\n",
    "    # If there are no (valid) credentials available, let the user log in.\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                CREDENTIALS_FILE, \n",
    "                scopes=['https://www.googleapis.com/auth/spreadsheets.readonly']\n",
    "            )\n",
    "            creds = flow.run_local_server(port=0)\n",
    "\n",
    "        # Save the credentials for the next run\n",
    "        with open(TOKEN_FILE, 'wb') as token:\n",
    "            pickle.dump(creds, token)\n",
    "\n",
    "    service = build('sheets', 'v4', credentials=creds)\n",
    "    return service\n",
    "\n",
    "def read_sheet_data(service, spreadsheet_id, range_name):\n",
    "    \"\"\"Reads data from a Google Sheet.\"\"\"\n",
    "    sheet = service.spreadsheets()\n",
    "    result = sheet.values().get(spreadsheetId=spreadsheet_id, range=range_name).execute()\n",
    "    values = result.get('values', [])\n",
    "    if not values:\n",
    "        print('No data found.')\n",
    "    return values\n",
    "\n",
    "def main():\n",
    "    service = get_google_sheets_service()\n",
    "\n",
    "    # Read data from the Google Sheet\n",
    "    data = read_sheet_data(service, SPREADSHEET_ID, READ_RANGE)\n",
    "\n",
    "    # Print the data\n",
    "    for row in data:\n",
    "        print(row)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normal accesing public sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Product      BrandType          Price\n",
      "0               TV   samsung 32''       Rs.38000\n",
      "1      gas cooker           usha        Rs.15000\n",
      "2      New Product      New Brand      New Price\n",
      "3  Another Product  Another Brand  Another Price\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# Replace with your Google Sheets URL\n",
    "SPREADSHEET_ID = '1lNZDwXKNlNkZiLWKksob55RE70e3IbSAhkR0W_pjGV4'\n",
    "SHEET_NAME = 'Sheet1'  # Adjust if necessary\n",
    "\n",
    "# Construct the URL for the Google Sheets API\n",
    "url = f'https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/gviz/tq?tqx=out:csv&sheet={SHEET_NAME}'\n",
    "\n",
    "def fetch_data_from_sheet(url):\n",
    "    \"\"\"Fetches CSV data from the Google Sheet URL.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.content.decode('utf-8')\n",
    "    else:\n",
    "        print('Failed to fetch data.')\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    csv_data = fetch_data_from_sheet(url)\n",
    "    if csv_data:\n",
    "        # Convert CSV data to DataFrame using StringIO\n",
    "        df = pd.read_csv(StringIO(csv_data))\n",
    "        print(df)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting user inputs and answer the quension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "You said: I won't buy gas cooker\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import pyttsx3\n",
    "import speech_recognition as sr\n",
    "\n",
    "# Google Sheets configuration\n",
    "SPREADSHEET_ID = '1lNZDwXKNlNkZiLWKksob55RE70e3IbSAhkR0W_pjGV4'\n",
    "SHEET_NAME = 'Sheet1'  # Adjust if necessary\n",
    "URL = f'https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/gviz/tq?tqx=out:csv&sheet={SHEET_NAME}'\n",
    "\n",
    "def fetch_data_from_sheet(url):\n",
    "    \"\"\"Fetches CSV data from the Google Sheet URL.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.content.decode('utf-8')\n",
    "    else:\n",
    "        print('Failed to fetch data.')\n",
    "        return None\n",
    "\n",
    "def speak(text):\n",
    "    \"\"\"Speaks the provided text.\"\"\"\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "def get_user_input():\n",
    "    \"\"\"Gets user input via speech recognition.\"\"\"\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening...\")\n",
    "        audio = recognizer.listen(source)\n",
    "        try:\n",
    "            text = recognizer.recognize_google(audio)\n",
    "            print(f\"You said: {text}\")\n",
    "            return text\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Sorry, I did not understand that.\")\n",
    "            return \"\"\n",
    "        except sr.RequestError:\n",
    "            print(\"Sorry, there was an issue with the speech recognition service.\")\n",
    "            return \"\"\n",
    "\n",
    "def main():\n",
    "    # Greet the user\n",
    "    speak(\"How can I help you?\")\n",
    "    \n",
    "    # Get user input\n",
    "    user_input = get_user_input()\n",
    "    \n",
    "    if not user_input:\n",
    "        return\n",
    "\n",
    "    # Extract keywords from user input\n",
    "    keywords = ['tv', 'gas cooker']  # Add more keywords as needed\n",
    "    matched_keywords = [keyword for keyword in keywords if keyword in user_input.lower()]\n",
    "\n",
    "    if not matched_keywords:\n",
    "        speak(\"Sorry, I couldn't find any matching items.\")\n",
    "        return\n",
    "\n",
    "    # Fetch data from Google Sheets\n",
    "    csv_data = fetch_data_from_sheet(URL)\n",
    "    if not csv_data:\n",
    "        speak(\"Failed to fetch data from the Google Sheet.\")\n",
    "        return\n",
    "    \n",
    "    # Convert CSV data to DataFrame\n",
    "    df = pd.read_csv(StringIO(csv_data))\n",
    "    \n",
    "    # Check for matches in DataFrame\n",
    "    for keyword in matched_keywords:\n",
    "        matched_rows = df[df['Product'].str.contains(keyword, case=False, na=False)]\n",
    "        if not matched_rows.empty:\n",
    "            for _, row in matched_rows.iterrows():\n",
    "                product = row['Product']\n",
    "                brand_type = row['BrandType']\n",
    "                price = row['Price']\n",
    "                details = f\"We have {product}, {brand_type} with the price {price}\"\n",
    "                speak(details)\n",
    "        else:\n",
    "            speak(f\"Sorry, we don't have information on {keyword}.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## update google sheet accesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "You said: goodbye fridge\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import pyttsx3\n",
    "import speech_recognition as sr\n",
    "\n",
    "# Google Sheets configuration\n",
    "SPREADSHEET_ID = '1lNZDwXKNlNkZiLWKksob55RE70e3IbSAhkR0W_pjGV4'\n",
    "SHEET_NAME = 'Sheet1'  # Adjust if necessary\n",
    "URL = f'https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/gviz/tq?tqx=out:csv&sheet={SHEET_NAME}'\n",
    "\n",
    "def fetch_data_from_sheet(url):\n",
    "    \"\"\"Fetches CSV data from the Google Sheet URL.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.content.decode('utf-8')\n",
    "    else:\n",
    "        print('Failed to fetch data.')\n",
    "        return None\n",
    "\n",
    "def speak(text):\n",
    "    \"\"\"Speaks the provided text.\"\"\"\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "def get_user_input():\n",
    "    \"\"\"Gets user input via speech recognition.\"\"\"\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening...\")\n",
    "        audio = recognizer.listen(source)\n",
    "        try:\n",
    "            text = recognizer.recognize_google(audio)\n",
    "            print(f\"You said: {text}\")\n",
    "            return text\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Sorry, I did not understand that.\")\n",
    "            return \"\"\n",
    "        except sr.RequestError:\n",
    "            print(\"Sorry, there was an issue with the speech recognition service.\")\n",
    "            return \"\"\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Preprocess the DataFrame to handle empty rows and group product details.\"\"\"\n",
    "    df = df.fillna('')\n",
    "    df['Product'] = df['Product'].replace('', pd.NA).ffill()\n",
    "    return df.dropna(subset=['Product'])\n",
    "\n",
    "def main():\n",
    "    # Greet the user\n",
    "    speak(\"How can I help you?\")\n",
    "    \n",
    "    # Get user input\n",
    "    user_input = get_user_input()\n",
    "    \n",
    "    if not user_input:\n",
    "        return\n",
    "\n",
    "    # Extract keywords from user input\n",
    "    keywords = ['tv', 'gas cooker', 'fridge']  # Add more keywords as needed\n",
    "    matched_keywords = [keyword for keyword in keywords if keyword in user_input.lower()]\n",
    "\n",
    "    if not matched_keywords:\n",
    "        speak(\"Sorry, I couldn't find any matching items.\")\n",
    "        return\n",
    "\n",
    "    # Fetch data from Google Sheets\n",
    "    csv_data = fetch_data_from_sheet(URL)\n",
    "    if not csv_data:\n",
    "        speak(\"Failed to fetch data from the Google Sheet.\")\n",
    "        return\n",
    "    \n",
    "    # Convert CSV data to DataFrame\n",
    "    df = pd.read_csv(StringIO(csv_data))\n",
    "    \n",
    "    # Preprocess the data\n",
    "    df = preprocess_data(df)\n",
    "    \n",
    "    # Check for matches in DataFrame\n",
    "    for keyword in matched_keywords:\n",
    "        matched_rows = df[df['Product'].str.contains(keyword, case=False, na=False)]\n",
    "        if not matched_rows.empty:\n",
    "            for _, row in matched_rows.iterrows():\n",
    "                product = row['Product']\n",
    "                brand_type = row['BrandType']\n",
    "                price = row['Price']\n",
    "                details = f\"We have {product}, {brand_type} with the price {price}\"\n",
    "                speak(details)\n",
    "        else:\n",
    "            speak(f\"Sorry, we don't have information on {keyword}.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## continuse run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Sorry, I did not understand that.\n",
      "Listening...\n",
      "You said: I won't buy TV\n",
      "Listening...\n",
      "You said: buy gas cooker\n",
      "Listening...\n",
      "You said: I won't buy gas cooker\n",
      "Listening...\n",
      "You said: goodbye TV\n",
      "Listening...\n",
      "You said: I want bit\n",
      "Listening...\n",
      "You said: I won't buy fridge\n",
      "Listening...\n",
      "You said: I won't buy fridge\n",
      "Listening...\n",
      "You said: I won't buy gas cooker\n",
      "Listening...\n",
      "You said: I won't buy gas cook\n",
      "Listening...\n",
      "You said: I won't buy gas cooker\n",
      "Listening...\n",
      "You said: I want buy a gas cooker\n",
      "Listening...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 101\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 101\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 95\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Ask if the user wants more information\u001b[39;00m\n\u001b[0;32m     94\u001b[0m speak(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAny other information you want to know?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 95\u001b[0m user_input \u001b[38;5;241m=\u001b[39m \u001b[43mget_user_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m user_input\u001b[38;5;241m.\u001b[39mlower():\n\u001b[0;32m     97\u001b[0m     speak(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThank you! Have a great day!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[15], line 32\u001b[0m, in \u001b[0;36mget_user_input\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sr\u001b[38;5;241m.\u001b[39mMicrophone() \u001b[38;5;28;01mas\u001b[39;00m source:\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mListening...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 32\u001b[0m     audio \u001b[38;5;241m=\u001b[39m \u001b[43mrecognizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m         text \u001b[38;5;241m=\u001b[39m recognizer\u001b[38;5;241m.\u001b[39mrecognize_google(audio)\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\face_rec\\Lib\\site-packages\\speech_recognition\\__init__.py:491\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mand\u001b[39;00m elapsed_time \u001b[38;5;241m>\u001b[39m timeout:\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WaitTimeoutError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlistening timed out while waiting for phrase to start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 491\u001b[0m buffer \u001b[38;5;241m=\u001b[39m \u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[0;32m    493\u001b[0m frames\u001b[38;5;241m.\u001b[39mappend(buffer)\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\face_rec\\Lib\\site-packages\\speech_recognition\\__init__.py:199\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyaudio_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\face_rec\\Lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import pyttsx3\n",
    "import speech_recognition as sr\n",
    "\n",
    "# Google Sheets configuration\n",
    "SPREADSHEET_ID = '1lNZDwXKNlNkZiLWKksob55RE70e3IbSAhkR0W_pjGV4'\n",
    "SHEET_NAME = 'Sheet1'  # Adjust if necessary\n",
    "URL = f'https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/gviz/tq?tqx=out:csv&sheet={SHEET_NAME}'\n",
    "\n",
    "def fetch_data_from_sheet(url):\n",
    "    \"\"\"Fetches CSV data from the Google Sheet URL.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.content.decode('utf-8')\n",
    "    else:\n",
    "        print('Failed to fetch data.')\n",
    "        return None\n",
    "\n",
    "def speak(text):\n",
    "    \"\"\"Speaks the provided text.\"\"\"\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "def get_user_input():\n",
    "    \"\"\"Gets user input via speech recognition.\"\"\"\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening...\")\n",
    "        audio = recognizer.listen(source)\n",
    "        try:\n",
    "            text = recognizer.recognize_google(audio)\n",
    "            print(f\"You said: {text}\")\n",
    "            return text\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Sorry, I did not understand that.\")\n",
    "            return \"\"\n",
    "        except sr.RequestError:\n",
    "            print(\"Sorry, there was an issue with the speech recognition service.\")\n",
    "            return \"\"\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Preprocess the DataFrame to handle empty rows and group product details.\"\"\"\n",
    "    df = df.fillna('')\n",
    "    df['Product'] = df['Product'].replace('', pd.NA).ffill()\n",
    "    return df.dropna(subset=['Product'])\n",
    "\n",
    "def main():\n",
    "    # Fetch data from Google Sheets\n",
    "    csv_data = fetch_data_from_sheet(URL)\n",
    "    if not csv_data:\n",
    "        speak(\"Failed to fetch data from the Google Sheet.\")\n",
    "        return\n",
    "    \n",
    "    # Convert CSV data to DataFrame\n",
    "    df = pd.read_csv(StringIO(csv_data))\n",
    "    \n",
    "    # Preprocess the data\n",
    "    df = preprocess_data(df)\n",
    "    \n",
    "    while True:\n",
    "        # Greet the user\n",
    "        speak(\"How can I help you?\")\n",
    "        \n",
    "        # Get user input\n",
    "        user_input = get_user_input()\n",
    "        \n",
    "        if not user_input:\n",
    "            continue\n",
    "\n",
    "        # Extract keywords from user input\n",
    "        keywords = ['tv', 'gas cooker', 'fridge']  # Add more keywords as needed\n",
    "        matched_keywords = [keyword for keyword in keywords if keyword in user_input.lower()]\n",
    "\n",
    "        if not matched_keywords:\n",
    "            speak(\"Sorry, I couldn't find any matching items.\")\n",
    "        else:\n",
    "            # Check for matches in DataFrame\n",
    "            for keyword in matched_keywords:\n",
    "                matched_rows = df[df['Product'].str.contains(keyword, case=False, na=False)]\n",
    "                if not matched_rows.empty:\n",
    "                    for _, row in matched_rows.iterrows():\n",
    "                        product = row['Product']\n",
    "                        brand_type = row['BrandType']\n",
    "                        price = row['Price']\n",
    "                        details = f\"We have {product}, {brand_type} with the price {price}\"\n",
    "                        speak(details)\n",
    "                else:\n",
    "                    speak(f\"Sorry, we don't have information on {keyword}.\")\n",
    "        \n",
    "        # Ask if the user wants more information\n",
    "        speak(\"Any other information you want to know?\")\n",
    "        user_input = get_user_input()\n",
    "        if 'no' in user_input.lower():\n",
    "            speak(\"Thank you! Have a great day!\")\n",
    "            break\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## update code with more key words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "You said: buy a TV I won't buy a TV\n",
      "Listening...\n",
      "You said: I would buy a fridge\n",
      "Listening...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 112\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 112\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 75\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     72\u001b[0m speak(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow can I help you?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Get user input\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m user_input \u001b[38;5;241m=\u001b[39m \u001b[43mget_user_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m user_input:\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[17], line 32\u001b[0m, in \u001b[0;36mget_user_input\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sr\u001b[38;5;241m.\u001b[39mMicrophone() \u001b[38;5;28;01mas\u001b[39;00m source:\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mListening...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 32\u001b[0m     audio \u001b[38;5;241m=\u001b[39m \u001b[43mrecognizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m         text \u001b[38;5;241m=\u001b[39m recognizer\u001b[38;5;241m.\u001b[39mrecognize_google(audio)\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\face_rec\\Lib\\site-packages\\speech_recognition\\__init__.py:491\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mand\u001b[39;00m elapsed_time \u001b[38;5;241m>\u001b[39m timeout:\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WaitTimeoutError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlistening timed out while waiting for phrase to start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 491\u001b[0m buffer \u001b[38;5;241m=\u001b[39m \u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[0;32m    493\u001b[0m frames\u001b[38;5;241m.\u001b[39mappend(buffer)\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\face_rec\\Lib\\site-packages\\speech_recognition\\__init__.py:199\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyaudio_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\face_rec\\Lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import pyttsx3\n",
    "import speech_recognition as sr\n",
    "\n",
    "# Google Sheets configuration\n",
    "SPREADSHEET_ID = '1lNZDwXKNlNkZiLWKksob55RE70e3IbSAhkR0W_pjGV4'\n",
    "SHEET_NAME = 'Sheet1'  # Adjust if necessary\n",
    "URL = f'https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/gviz/tq?tqx=out:csv&sheet={SHEET_NAME}'\n",
    "\n",
    "def fetch_data_from_sheet(url):\n",
    "    \"\"\"Fetches CSV data from the Google Sheet URL.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.content.decode('utf-8')\n",
    "    else:\n",
    "        print('Failed to fetch data.')\n",
    "        return None\n",
    "\n",
    "def speak(text):\n",
    "    \"\"\"Speaks the provided text.\"\"\"\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "def get_user_input():\n",
    "    \"\"\"Gets user input via speech recognition.\"\"\"\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening...\")\n",
    "        audio = recognizer.listen(source)\n",
    "        try:\n",
    "            text = recognizer.recognize_google(audio)\n",
    "            print(f\"You said: {text}\")\n",
    "            return text\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Sorry, I did not understand that.\")\n",
    "            return \"\"\n",
    "        except sr.RequestError:\n",
    "            print(\"Sorry, there was an issue with the speech recognition service.\")\n",
    "            return \"\"\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Preprocess the DataFrame to handle empty rows and group product details.\"\"\"\n",
    "    df = df.fillna('')\n",
    "    df['Product'] = df['Product'].replace('', pd.NA).ffill()\n",
    "    return df.dropna(subset=['Product'])\n",
    "\n",
    "def main():\n",
    "    # Fetch data from Google Sheets\n",
    "    csv_data = fetch_data_from_sheet(URL)\n",
    "    if not csv_data:\n",
    "        speak(\"Failed to fetch data from the Google Sheet.\")\n",
    "        return\n",
    "    \n",
    "    # Convert CSV data to DataFrame\n",
    "    df = pd.read_csv(StringIO(csv_data))\n",
    "    \n",
    "    # Preprocess the data\n",
    "    df = preprocess_data(df)\n",
    "    \n",
    "    # Dictionary mapping keywords to products\n",
    "    product_keywords = {\n",
    "        'tv': ['tv', 'television'],\n",
    "        'gas cooker': ['gas cook', 'gas cooker', 'gascooker'],\n",
    "        'fridge': ['fridge', 'refrigerator']\n",
    "    }\n",
    "\n",
    "    while True:\n",
    "        # Greet the user\n",
    "        speak(\"How can I help you?\")\n",
    "        \n",
    "        # Get user input\n",
    "        user_input = get_user_input()\n",
    "        \n",
    "        if not user_input:\n",
    "            continue\n",
    "\n",
    "        # Find matching products\n",
    "        matched_products = []\n",
    "        for product, keywords in product_keywords.items():\n",
    "            for keyword in keywords:\n",
    "                if keyword in user_input.lower():\n",
    "                    matched_products.append(product)\n",
    "                    break\n",
    "\n",
    "        if not matched_products:\n",
    "            speak(\"Sorry, I couldn't find any matching items.\")\n",
    "        else:\n",
    "            # Check for matches in DataFrame\n",
    "            for product in matched_products:\n",
    "                matched_rows = df[df['Product'].str.contains(product, case=False, na=False)]\n",
    "                if not matched_rows.empty:\n",
    "                    for _, row in matched_rows.iterrows():\n",
    "                        product_name = row['Product']\n",
    "                        brand_type = row['BrandType']\n",
    "                        price = row['Price']\n",
    "                        details = f\"We have {product_name}, {brand_type} with the price {price}\"\n",
    "                        speak(details)\n",
    "                else:\n",
    "                    speak(f\"Sorry, we don't have information on {product}.\")\n",
    "        \n",
    "        # Ask if the user wants more information\n",
    "        speak(\"Any other information you want to know?\")\n",
    "        user_input = get_user_input()\n",
    "        if 'no' in user_input.lower():\n",
    "            speak(\"Thank you! Have a great day!\")\n",
    "            break\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## error fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "You said: I want buy TV\n",
      "Listening...\n",
      "You said: no\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import pyttsx3\n",
    "import speech_recognition as sr\n",
    "\n",
    "# Google Sheets configuration\n",
    "SPREADSHEET_ID = '1lNZDwXKNlNkZiLWKksob55RE70e3IbSAhkR0W_pjGV4'\n",
    "SHEET_NAME = 'Sheet1'  # Adjust if necessary\n",
    "URL = f'https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/gviz/tq?tqx=out:csv&sheet={SHEET_NAME}'\n",
    "\n",
    "def fetch_data_from_sheet(url):\n",
    "    \"\"\"Fetches CSV data from the Google Sheet URL.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.content.decode('utf-8')\n",
    "    else:\n",
    "        print('Failed to fetch data.')\n",
    "        return None\n",
    "\n",
    "def speak(text):\n",
    "    \"\"\"Speaks the provided text.\"\"\"\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "def get_user_input():\n",
    "    \"\"\"Gets user input via speech recognition.\"\"\"\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening...\")\n",
    "        audio = recognizer.listen(source)\n",
    "        try:\n",
    "            text = recognizer.recognize_google(audio)\n",
    "            print(f\"You said: {text}\")\n",
    "            return text\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Sorry, I did not understand that.\")\n",
    "            return \"\"\n",
    "        except sr.RequestError:\n",
    "            print(\"Sorry, there was an issue with the speech recognition service.\")\n",
    "            return \"\"\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Preprocess the DataFrame to handle empty rows and group product details.\"\"\"\n",
    "    df = df.fillna('')\n",
    "    df['Product'] = df['Product'].replace('', pd.NA).ffill()\n",
    "    return df.dropna(subset=['Product'])\n",
    "\n",
    "def main():\n",
    "    # Fetch data from Google Sheets\n",
    "    csv_data = fetch_data_from_sheet(URL)\n",
    "    if not csv_data:\n",
    "        speak(\"Failed to fetch data from the Google Sheet.\")\n",
    "        return\n",
    "    \n",
    "    # Convert CSV data to DataFrame\n",
    "    df = pd.read_csv(StringIO(csv_data))\n",
    "    \n",
    "    # Preprocess the data\n",
    "    df = preprocess_data(df)\n",
    "    \n",
    "    # Dictionary mapping keywords to products\n",
    "    product_keywords = {\n",
    "        'tv': ['tv', 'television'],\n",
    "        'gas cooker': ['gas cook', 'gas cooker', 'gascooker'],\n",
    "        'fridge': ['fridge', 'refrigerator']\n",
    "    }\n",
    "\n",
    "    while True:\n",
    "        # Greet the user\n",
    "        speak(\"How can I help you?\")\n",
    "        \n",
    "        # Get user input\n",
    "        user_input = get_user_input()\n",
    "        \n",
    "        if not user_input:\n",
    "            continue\n",
    "\n",
    "        while True:\n",
    "            # Find matching products\n",
    "            matched_products = []\n",
    "            for product, keywords in product_keywords.items():\n",
    "                for keyword in keywords:\n",
    "                    if keyword in user_input.lower():\n",
    "                        matched_products.append(product)\n",
    "                        break\n",
    "\n",
    "            if not matched_products:\n",
    "                speak(\"Sorry, I couldn't find any matching items.\")\n",
    "            else:\n",
    "                # Check for matches in DataFrame\n",
    "                for product in matched_products:\n",
    "                    matched_rows = df[df['Product'].str.contains(product, case=False, na=False)]\n",
    "                    if not matched_rows.empty:\n",
    "                        for _, row in matched_rows.iterrows():\n",
    "                            product_name = row['Product']\n",
    "                            brand_type = row['BrandType']\n",
    "                            price = row['Price']\n",
    "                            details = f\"We have {product_name}, {brand_type} with the price {price}\"\n",
    "                            speak(details)\n",
    "                    else:\n",
    "                        speak(f\"Sorry, we don't have information on {product}.\")\n",
    "            \n",
    "            # Ask if the user wants more information\n",
    "            speak(\"Any other information you want to know?\")\n",
    "            user_input = get_user_input()\n",
    "            if 'no' in user_input.lower() or 'nothing' in user_input.lower():\n",
    "                speak(\"Thank you! Have a great day!\")\n",
    "                return  # Exit the main function\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine code (google sheet accessing with trainde model accessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: i want buya tv. Let me check the latest price for you.\n",
      "We have TV, samsung 32'' with the price Rs.38000\n",
      "We have TV, samsung 48'' with the price Rs.48000\n",
      "We have TV, LG 72\" with the price Rs.60000\n",
      "Model: i want buy a rice cooker. Let me check the available rice cookers for you.\n",
      "Sorry, I couldn't find any matching items.\n",
      "Model: how about fridge? Sure, let me see what fridge we have in stock.\n",
      "We have Fridge, sisil with the price Rs.78000\n",
      "We have Fridge, samsung with the price Rs.90000\n",
      "Model: how about tv? Sure, let me check the latest price for you.\n",
      "We have TV, samsung 32'' with the price Rs.38000\n",
      "We have TV, samsung 48'' with the price Rs.48000\n",
      "We have TV, LG 72\" with the price Rs.60000\n",
      "Model: i want buy a rice cooker. Let me check the available rice cookers for you.\n",
      "Sorry, I couldn't find any matching items.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cannot reshape tensor of 0 elements into shape [-1, 0] because the unspecified dimension size -1 can be any value and is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 118\u001b[0m\n\u001b[0;32m    115\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 118\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 84\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# Generate a response from the model\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# Find matching products\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 42\u001b[0m, in \u001b[0;36mgenerate_response\u001b[1;34m(prompt, max_length)\u001b[0m\n\u001b[0;32m     39\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 42\u001b[0m     output_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(output_ids[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m generated_text\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\transformers\\generation\\utils.py:1989\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1981\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   1982\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1983\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[0;32m   1984\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   1985\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1986\u001b[0m     )\n\u001b[0;32m   1988\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[1;32m-> 1989\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample(\n\u001b[0;32m   1990\u001b[0m         input_ids,\n\u001b[0;32m   1991\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   1992\u001b[0m         logits_warper\u001b[38;5;241m=\u001b[39mprepared_logits_warper,\n\u001b[0;32m   1993\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   1994\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   1995\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   1996\u001b[0m         streamer\u001b[38;5;241m=\u001b[39mstreamer,\n\u001b[0;32m   1997\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1998\u001b[0m     )\n\u001b[0;32m   2000\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[0;32m   2001\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2003\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   2004\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample\n\u001b[0;32m   2005\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2006\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\transformers\\generation\\utils.py:2932\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[0;32m   2929\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[0;32m   2931\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[1;32m-> 2932\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   2934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[0;32m   2935\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1315\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1307\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1309\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[0;32m   1310\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1315\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1326\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1330\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1332\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1004\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1002\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarn_if_padding_and_no_attention_mask(input_ids, attention_mask)\n\u001b[0;32m   1003\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m-> 1004\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m \u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1005\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: cannot reshape tensor of 0 elements into shape [-1, 0] because the unspecified dimension size -1 can be any value and is ambiguous"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "# Google Sheets configuration\n",
    "SPREADSHEET_ID = '1lNZDwXKNlNkZiLWKksob55RE70e3IbSAhkR0W_pjGV4'\n",
    "SHEET_NAME = 'Sheet1'  # Adjust if necessary\n",
    "URL = f'https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/gviz/tq?tqx=out:csv&sheet={SHEET_NAME}'\n",
    "\n",
    "# Load the trained model and tokenizer\n",
    "model_name = 'custom_seller_bot_model'  # Directory where your trained model is saved\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "def fetch_data_from_sheet(url):\n",
    "    \"\"\"Fetches CSV data from the Google Sheet URL.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.content.decode('utf-8')\n",
    "    else:\n",
    "        print('Failed to fetch data.')\n",
    "        return None\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Preprocess the DataFrame to handle empty rows and group product details.\"\"\"\n",
    "    df = df.fillna('')\n",
    "    df['Product'] = df['Product'].replace('', pd.NA).ffill()\n",
    "    return df.dropna(subset=['Product'])\n",
    "\n",
    "def generate_response(prompt, max_length=100):\n",
    "    \"\"\"Generates a response from the GPT-2 model.\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_length=max_length,\n",
    "            num_return_sequences=1,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "    generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "def main():\n",
    "    # Fetch data from Google Sheets\n",
    "    csv_data = fetch_data_from_sheet(URL)\n",
    "    if not csv_data:\n",
    "        print(\"Failed to fetch data from the Google Sheet.\")\n",
    "        return\n",
    "    \n",
    "    # Convert CSV data to DataFrame\n",
    "    df = pd.read_csv(StringIO(csv_data))\n",
    "    \n",
    "    # Preprocess the data\n",
    "    df = preprocess_data(df)\n",
    "    \n",
    "    # Dictionary mapping keywords to products\n",
    "    product_keywords = {\n",
    "        'tv': ['tv', 'television'],\n",
    "        'gas cooker': ['gas cook', 'gas cooker', 'gascooker'],\n",
    "        'fridge': ['fridge', 'refrigerator']\n",
    "    }\n",
    "\n",
    "    while True:\n",
    "        # Get user input\n",
    "        user_input = input(\"You: \")\n",
    "        \n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"Exiting...\")\n",
    "            break\n",
    "\n",
    "        # Generate a response from the model\n",
    "        response = generate_response(user_input)\n",
    "        print(f\"Model: {response}\")\n",
    "\n",
    "        # Find matching products\n",
    "        matched_products = []\n",
    "        for product, keywords in product_keywords.items():\n",
    "            for keyword in keywords:\n",
    "                if keyword in user_input.lower():\n",
    "                    matched_products.append(product)\n",
    "                    break\n",
    "\n",
    "        if matched_products:\n",
    "            # Check for matches in DataFrame\n",
    "            for product in matched_products:\n",
    "                matched_rows = df[df['Product'].str.contains(product, case=False, na=False)]\n",
    "                if not matched_rows.empty:\n",
    "                    for _, row in matched_rows.iterrows():\n",
    "                        product_name = row['Product']\n",
    "                        brand_type = row['BrandType']\n",
    "                        price = row['Price']\n",
    "                        details = f\"We have {product_name}, {brand_type} with the price {price}\"\n",
    "                        print(details)\n",
    "                else:\n",
    "                    print(f\"Sorry, we don't have information on {product}.\")\n",
    "        else:\n",
    "            print(\"Sorry, I couldn't find any matching items.\")\n",
    "        \n",
    "        # Ask if the user wants more information\n",
    "        user_input = input(\"Any other information you want to know? (Type 'no' to exit): \")\n",
    "        if 'no' in user_input.lower() or 'nothing' in user_input.lower():\n",
    "            print(\"Thank you! Have a great day!\")\n",
    "            break\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## updatd code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Changes:\n",
    "Load Model and Tokenizer: Added generate_response function to get model-generated responses.\n",
    "User Input Handling: First, the user input is processed by the model, and then the response from the model is used for keyword extraction.\n",
    "Keyword Extraction: Keywords are searched in the model’s response to determine which products might be of interest.\n",
    "Data Fetching and Processing: Handles CSV data fetching and preprocessing as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: i want buy a tv. Let me check the latest price for you.\n",
      "We have TV, samsung 32'' with the price Rs.38000\n",
      "We have TV, samsung 48'' with the price Rs.48000\n",
      "We have TV, LG 72\" with the price Rs.60000\n",
      "Model: how about rice cooker? Sure, let me see what rice cookers we have in stock.\n",
      "Sorry, I couldn't find any matching items.\n",
      "Model: how about gas cooker? Sure, let me see what gas cookers we have in stock.\n",
      "We have gas cooker , usha  with the price Rs.15000\n",
      "We have gas cooker , samsung with the price Rs24000\n",
      "Model: do you have tv? Sure, let me see what tv's we have in stock.\n",
      "We have TV, samsung 32'' with the price Rs.38000\n",
      "We have TV, samsung 48'' with the price Rs.48000\n",
      "We have TV, LG 72\" with the price Rs.60000\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cannot reshape tensor of 0 elements into shape [-1, 0] because the unspecified dimension size -1 can be any value and is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 110\u001b[0m\n\u001b[0;32m    107\u001b[0m                     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSorry, we don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have information on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproduct\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 110\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 82\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# Generate response from the model\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m model_response \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_response\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Process the model response to find matching products\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[7], line 34\u001b[0m, in \u001b[0;36mgenerate_response\u001b[1;34m(prompt, model, tokenizer, max_length)\u001b[0m\n\u001b[0;32m     31\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 34\u001b[0m     output_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(output_ids[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m generated_text\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\transformers\\generation\\utils.py:1989\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1981\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   1982\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1983\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[0;32m   1984\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   1985\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1986\u001b[0m     )\n\u001b[0;32m   1988\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[1;32m-> 1989\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample(\n\u001b[0;32m   1990\u001b[0m         input_ids,\n\u001b[0;32m   1991\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   1992\u001b[0m         logits_warper\u001b[38;5;241m=\u001b[39mprepared_logits_warper,\n\u001b[0;32m   1993\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   1994\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   1995\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   1996\u001b[0m         streamer\u001b[38;5;241m=\u001b[39mstreamer,\n\u001b[0;32m   1997\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1998\u001b[0m     )\n\u001b[0;32m   2000\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[0;32m   2001\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2003\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   2004\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample\n\u001b[0;32m   2005\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2006\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\transformers\\generation\\utils.py:2932\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[0;32m   2929\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[0;32m   2931\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[1;32m-> 2932\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   2934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[0;32m   2935\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1315\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1307\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1309\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[0;32m   1310\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1315\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1326\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1330\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1332\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1004\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1002\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarn_if_padding_and_no_attention_mask(input_ids, attention_mask)\n\u001b[0;32m   1003\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m-> 1004\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m \u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1005\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: cannot reshape tensor of 0 elements into shape [-1, 0] because the unspecified dimension size -1 can be any value and is ambiguous"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "# Google Sheets configuration\n",
    "SPREADSHEET_ID = '1lNZDwXKNlNkZiLWKksob55RE70e3IbSAhkR0W_pjGV4'\n",
    "SHEET_NAME = 'Sheet1'  # Adjust if necessary\n",
    "URL = f'https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/gviz/tq?tqx=out:csv&sheet={SHEET_NAME}'\n",
    "\n",
    "def fetch_data_from_sheet(url):\n",
    "    \"\"\"Fetches CSV data from the Google Sheet URL.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.content.decode('utf-8')\n",
    "    else:\n",
    "        print('Failed to fetch data.')\n",
    "        return None\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Preprocess the DataFrame to handle empty rows and group product details.\"\"\"\n",
    "    df = df.fillna('')\n",
    "    df['Product'] = df['Product'].replace('', pd.NA).ffill()\n",
    "    return df.dropna(subset=['Product'])\n",
    "\n",
    "def generate_response(prompt, model, tokenizer, max_length=100):\n",
    "    \"\"\"Generates a response from the model based on the prompt.\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_length=max_length,\n",
    "            num_return_sequences=1,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "\n",
    "    generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "def main():\n",
    "    # Load the trained model and tokenizer\n",
    "    model_name = 'custom_seller_bot_model'  # Directory where your trained model is saved\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "    model.eval()\n",
    "\n",
    "    # Fetch data from Google Sheets\n",
    "    csv_data = fetch_data_from_sheet(URL)\n",
    "    if not csv_data:\n",
    "        print(\"Failed to fetch data from the Google Sheet.\")\n",
    "        return\n",
    "    \n",
    "    # Convert CSV data to DataFrame\n",
    "    df = pd.read_csv(StringIO(csv_data))\n",
    "    \n",
    "    # Preprocess the data\n",
    "    df = preprocess_data(df)\n",
    "\n",
    "    # Dictionary mapping keywords to products\n",
    "    product_keywords = {\n",
    "        'tv': ['tv', 'television'],\n",
    "        'gas cooker': ['gas cook', 'gas cooker', 'gascooker'],\n",
    "        'fridge': ['fridge', 'refrigerator']\n",
    "    }\n",
    "\n",
    "    while True:\n",
    "        # Get user input\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"Exiting...\")\n",
    "            break\n",
    "\n",
    "        # Generate response from the model\n",
    "        model_response = generate_response(user_input, model, tokenizer)\n",
    "        print(f\"Model: {model_response}\")\n",
    "\n",
    "        # Process the model response to find matching products\n",
    "        matched_products = []\n",
    "        for product, keywords in product_keywords.items():\n",
    "            for keyword in keywords:\n",
    "                if keyword in model_response.lower():\n",
    "                    matched_products.append(product)\n",
    "                    break\n",
    "\n",
    "        if not matched_products:\n",
    "            print(\"Sorry, I couldn't find any matching items.\")\n",
    "        else:\n",
    "            # Check for matches in DataFrame\n",
    "            for product in matched_products:\n",
    "                matched_rows = df[df['Product'].str.contains(product, case=False, na=False)]\n",
    "                if not matched_rows.empty:\n",
    "                    for _, row in matched_rows.iterrows():\n",
    "                        product_name = row['Product']\n",
    "                        brand_type = row['BrandType']\n",
    "                        price = row['Price']\n",
    "                        details = f\"We have {product_name}, {brand_type} with the price {price}\"\n",
    "                        print(details)\n",
    "                else:\n",
    "                    print(f\"Sorry, we don't have information on {product}.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To modify the code so that it dynamically extracts keywords from the Google Sheet and updates the keyword list in a separate file, you can follow these steps:\n",
    "\n",
    "Fetch and Extract Keywords Dynamically: Update the script to extract the product keywords from the Google Sheet.\n",
    "Save Keywords to a Separate File: Write the extracted keywords to a separate file.\n",
    "Update Keyword Matching: Adjust the product matching logic to use the dynamically extracted keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: i want buy a tv. Let me check the latest price for you.\n",
      "We have TV, samsung 32'' with the price Rs.38000\n",
      "We have TV, samsung 48'' with the price Rs.48000\n",
      "We have TV, LG 72\" with the price Rs.60000\n",
      "Model: how about gas cooker? Sure, let me see what gas cookers we have in stock.\n",
      "Sorry, I couldn't find any matching items.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cannot reshape tensor of 0 elements into shape [-1, 0] because the unspecified dimension size -1 can be any value and is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 108\u001b[0m\n\u001b[0;32m    105\u001b[0m                     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSorry, we don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have information on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproduct\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 108\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 85\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Generate response from the model\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m model_response \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_response\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Process the model response to find matching products\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 40\u001b[0m, in \u001b[0;36mgenerate_response\u001b[1;34m(prompt, model, tokenizer, max_length)\u001b[0m\n\u001b[0;32m     37\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 40\u001b[0m     output_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(output_ids[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m generated_text\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\transformers\\generation\\utils.py:1989\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1981\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   1982\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1983\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[0;32m   1984\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   1985\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1986\u001b[0m     )\n\u001b[0;32m   1988\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[1;32m-> 1989\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample(\n\u001b[0;32m   1990\u001b[0m         input_ids,\n\u001b[0;32m   1991\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   1992\u001b[0m         logits_warper\u001b[38;5;241m=\u001b[39mprepared_logits_warper,\n\u001b[0;32m   1993\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   1994\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   1995\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   1996\u001b[0m         streamer\u001b[38;5;241m=\u001b[39mstreamer,\n\u001b[0;32m   1997\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1998\u001b[0m     )\n\u001b[0;32m   2000\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[0;32m   2001\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2003\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   2004\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample\n\u001b[0;32m   2005\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2006\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\transformers\\generation\\utils.py:2932\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[0;32m   2929\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[0;32m   2931\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[1;32m-> 2932\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   2934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[0;32m   2935\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1315\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1307\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1309\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[0;32m   1310\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1315\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1326\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1330\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1332\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1004\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1002\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarn_if_padding_and_no_attention_mask(input_ids, attention_mask)\n\u001b[0;32m   1003\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m-> 1004\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m \u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1005\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: cannot reshape tensor of 0 elements into shape [-1, 0] because the unspecified dimension size -1 can be any value and is ambiguous"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "# Google Sheets configuration\n",
    "SPREADSHEET_ID = '1lNZDwXKNlNkZiLWKksob55RE70e3IbSAhkR0W_pjGV4'\n",
    "SHEET_NAME = 'Sheet1'  # Adjust if necessary\n",
    "URL = f'https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/gviz/tq?tqx=out:csv&sheet={SHEET_NAME}'\n",
    "\n",
    "def fetch_data_from_sheet(url):\n",
    "    \"\"\"Fetches CSV data from the Google Sheet URL.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.content.decode('utf-8')\n",
    "    else:\n",
    "        print('Failed to fetch data.')\n",
    "        return None\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Preprocess the DataFrame to handle empty rows and group product details.\"\"\"\n",
    "    df = df.fillna('')\n",
    "    df['Product'] = df['Product'].replace('', pd.NA).ffill()\n",
    "    return df.dropna(subset=['Product'])\n",
    "\n",
    "def save_keywords_to_file(keywords, filename='keywords.txt'):\n",
    "    \"\"\"Saves the extracted keywords to a file.\"\"\"\n",
    "    with open(filename, 'w') as file:\n",
    "        for keyword in keywords:\n",
    "            file.write(f\"{keyword}\\n\")\n",
    "\n",
    "def generate_response(prompt, model, tokenizer, max_length=100):\n",
    "    \"\"\"Generates a response from the model based on the prompt.\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_length=max_length,\n",
    "            num_return_sequences=1,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "\n",
    "    generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "def main():\n",
    "    # Load the trained model and tokenizer\n",
    "    model_name = 'custom_seller_bot_model'  # Directory where your trained model is saved\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "    model.eval()\n",
    "\n",
    "    # Fetch data from Google Sheets\n",
    "    csv_data = fetch_data_from_sheet(URL)\n",
    "    if not csv_data:\n",
    "        print(\"Failed to fetch data from the Google Sheet.\")\n",
    "        return\n",
    "    \n",
    "    # Convert CSV data to DataFrame\n",
    "    df = pd.read_csv(StringIO(csv_data))\n",
    "    \n",
    "    # Preprocess the data\n",
    "    df = preprocess_data(df)\n",
    "    \n",
    "    # Extract keywords from the first column of the DataFrame\n",
    "    keywords = df['Product'].dropna().unique().tolist()\n",
    "    save_keywords_to_file(keywords)\n",
    "\n",
    "    while True:\n",
    "        # Get user input\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"Exiting...\")\n",
    "            break\n",
    "\n",
    "        # Generate response from the model\n",
    "        model_response = generate_response(user_input, model, tokenizer)\n",
    "        print(f\"Model: {model_response}\")\n",
    "\n",
    "        # Process the model response to find matching products\n",
    "        matched_products = [keyword for keyword in keywords if keyword.lower() in model_response.lower()]\n",
    "\n",
    "        if not matched_products:\n",
    "            print(\"Sorry, I couldn't find any matching items.\")\n",
    "        else:\n",
    "            # Check for matches in DataFrame\n",
    "            for product in matched_products:\n",
    "                matched_rows = df[df['Product'].str.contains(product, case=False, na=False)]\n",
    "                if not matched_rows.empty:\n",
    "                    for _, row in matched_rows.iterrows():\n",
    "                        product_name = row['Product']\n",
    "                        brand_type = row['BrandType']\n",
    "                        price = row['Price']\n",
    "                        details = f\"We have {product_name}, {brand_type} with the price {price}\"\n",
    "                        print(details)\n",
    "                else:\n",
    "                    print(f\"Sorry, we don't have information on {product}.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: i want buy a gas cooker. Let me check the available gas cookers for you.\n",
      "Sorry, I couldn't find any matching items.\n",
      "Model: how about tv sets? Sure, let me see what tv sets we have in stock.\n",
      "We have TV, samsung 32'' with the price Rs.38000\n",
      "We have TV, samsung 48'' with the price Rs.48000\n",
      "We have TV, LG 72\" with the price Rs.60000\n",
      "Model: don't you have gas cooker? Sure, let me see what gas cookers we have in stock.\n",
      "Sorry, I couldn't find any matching items.\n",
      "Model: do you have offers on home entertainment? Let me check if we have any offers on home entertainment.\n",
      "Sorry, I couldn't find any matching items.\n",
      "Model: any offers going on? Sure, let me see what products we have in stock.\n",
      "Sorry, I couldn't find any matching items.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cannot reshape tensor of 0 elements into shape [-1, 0] because the unspecified dimension size -1 can be any value and is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 110\u001b[0m\n\u001b[0;32m    107\u001b[0m                     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSorry, we don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have information on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkeyword\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 110\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 87\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# Generate response from the model\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m model_response \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_response\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# Extract keywords from the model response\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[11], line 34\u001b[0m, in \u001b[0;36mgenerate_response\u001b[1;34m(prompt, model, tokenizer, max_length)\u001b[0m\n\u001b[0;32m     31\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 34\u001b[0m     output_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(output_ids[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m generated_text\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\transformers\\generation\\utils.py:1989\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1981\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   1982\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1983\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[0;32m   1984\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   1985\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1986\u001b[0m     )\n\u001b[0;32m   1988\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[1;32m-> 1989\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample(\n\u001b[0;32m   1990\u001b[0m         input_ids,\n\u001b[0;32m   1991\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   1992\u001b[0m         logits_warper\u001b[38;5;241m=\u001b[39mprepared_logits_warper,\n\u001b[0;32m   1993\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   1994\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   1995\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   1996\u001b[0m         streamer\u001b[38;5;241m=\u001b[39mstreamer,\n\u001b[0;32m   1997\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1998\u001b[0m     )\n\u001b[0;32m   2000\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[0;32m   2001\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2003\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   2004\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample\n\u001b[0;32m   2005\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2006\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\transformers\\generation\\utils.py:2932\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[0;32m   2929\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[0;32m   2931\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[1;32m-> 2932\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   2934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[0;32m   2935\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1315\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1307\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1309\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[0;32m   1310\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1315\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1326\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1330\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1332\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1004\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1002\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarn_if_padding_and_no_attention_mask(input_ids, attention_mask)\n\u001b[0;32m   1003\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m-> 1004\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m \u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1005\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: cannot reshape tensor of 0 elements into shape [-1, 0] because the unspecified dimension size -1 can be any value and is ambiguous"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "# Google Sheets configuration\n",
    "SPREADSHEET_ID = '1lNZDwXKNlNkZiLWKksob55RE70e3IbSAhkR0W_pjGV4'\n",
    "SHEET_NAME = 'Sheet1'  # Adjust if necessary\n",
    "URL = f'https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/gviz/tq?tqx=out:csv&sheet={SHEET_NAME}'\n",
    "\n",
    "def fetch_data_from_sheet(url):\n",
    "    \"\"\"Fetches CSV data from the Google Sheet URL.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.content.decode('utf-8')\n",
    "    else:\n",
    "        print('Failed to fetch data.')\n",
    "        return None\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Preprocess the DataFrame to handle empty rows and group product details.\"\"\"\n",
    "    df = df.fillna('')\n",
    "    df['Product'] = df['Product'].replace('', pd.NA).ffill()\n",
    "    return df.dropna(subset=['Product'])\n",
    "\n",
    "def generate_response(prompt, model, tokenizer, max_length=100):\n",
    "    \"\"\"Generates a response from the model based on the prompt.\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_length=max_length,\n",
    "            num_return_sequences=1,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "\n",
    "    generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "def extract_keywords_from_text(text, keywords):\n",
    "    \"\"\"Extracts keywords from the given text.\"\"\"\n",
    "    extracted_keywords = []\n",
    "    text_lower = text.lower()\n",
    "    for keyword in keywords:\n",
    "        if keyword.lower() in text_lower:\n",
    "            extracted_keywords.append(keyword)\n",
    "    return extracted_keywords\n",
    "\n",
    "def main():\n",
    "    # Load the trained model and tokenizer\n",
    "    model_name = 'custom_seller_bot_model'  # Directory where your trained model is saved\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "    model.eval()\n",
    "\n",
    "    # Fetch data from Google Sheets\n",
    "    csv_data = fetch_data_from_sheet(URL)\n",
    "    if not csv_data:\n",
    "        print(\"Failed to fetch data from the Google Sheet.\")\n",
    "        return\n",
    "    \n",
    "    # Convert CSV data to DataFrame\n",
    "    df = pd.read_csv(StringIO(csv_data))\n",
    "    \n",
    "    # Preprocess the data\n",
    "    df = preprocess_data(df)\n",
    "    \n",
    "    # Extract keywords from the DataFrame\n",
    "    keywords = df['Product'].dropna().unique().tolist()\n",
    "\n",
    "    while True:\n",
    "        # Get user input\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"Exiting...\")\n",
    "            break\n",
    "\n",
    "        # Generate response from the model\n",
    "        model_response = generate_response(user_input, model, tokenizer)\n",
    "        print(f\"Model: {model_response}\")\n",
    "\n",
    "        # Extract keywords from the model response\n",
    "        matched_keywords = extract_keywords_from_text(model_response, keywords)\n",
    "\n",
    "        if not matched_keywords:\n",
    "            print(\"Sorry, I couldn't find any matching items.\")\n",
    "        else:\n",
    "            # Check for matches in DataFrame\n",
    "            for keyword in matched_keywords:\n",
    "                matched_rows = df[df['Product'].str.contains(keyword, case=False, na=False)]\n",
    "                if not matched_rows.empty:\n",
    "                    for _, row in matched_rows.iterrows():\n",
    "                        product_name = row['Product']\n",
    "                        brand_type = row['BrandType']\n",
    "                        price = row['Price']\n",
    "                        details = f\"We have {product_name}, {brand_type} with the price {price}\"\n",
    "                        print(details)\n",
    "                else:\n",
    "                    print(f\"Sorry, we don't have information on {keyword}.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords from DataFrame: ['TV', 'gas cooker ', 'Fridge', 'rice cooker ']\n",
      "DataFrame contents:\n",
      "        Product     BrandType     Price\n",
      "0            TV  samsung 32''  Rs.38000\n",
      "1            TV  samsung 48''  Rs.48000\n",
      "2            TV        LG 72\"  Rs.60000\n",
      "3   gas cooker          usha   Rs.15000\n",
      "4   gas cooker        samsung   Rs24000\n",
      "5        Fridge         sisil  Rs.78000\n",
      "6        Fridge       samsung  Rs.90000\n",
      "7  rice cooker        samsung   Rs.6700\n",
      "Model: i want buy a gas cooker. Let me check the latest price for you.\n",
      "Keywords extracted from response: []\n",
      "Sorry, I couldn't find any matching items.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cannot reshape tensor of 0 elements into shape [-1, 0] because the unspecified dimension size -1 can be any value and is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 114\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSorry, I couldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find any matching items.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 114\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 88\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# Generate response from the model\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m model_response \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_response\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# Extract keywords from the model response\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[15], line 34\u001b[0m, in \u001b[0;36mgenerate_response\u001b[1;34m(prompt, model, tokenizer, max_length)\u001b[0m\n\u001b[0;32m     31\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 34\u001b[0m     output_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(output_ids[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m generated_text\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\transformers\\generation\\utils.py:1989\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1981\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   1982\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1983\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[0;32m   1984\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   1985\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1986\u001b[0m     )\n\u001b[0;32m   1988\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[1;32m-> 1989\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample(\n\u001b[0;32m   1990\u001b[0m         input_ids,\n\u001b[0;32m   1991\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   1992\u001b[0m         logits_warper\u001b[38;5;241m=\u001b[39mprepared_logits_warper,\n\u001b[0;32m   1993\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   1994\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   1995\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   1996\u001b[0m         streamer\u001b[38;5;241m=\u001b[39mstreamer,\n\u001b[0;32m   1997\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1998\u001b[0m     )\n\u001b[0;32m   2000\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[0;32m   2001\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2003\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   2004\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample\n\u001b[0;32m   2005\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2006\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\transformers\\generation\\utils.py:2932\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[0;32m   2929\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[0;32m   2931\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[1;32m-> 2932\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   2934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[0;32m   2935\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1315\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1307\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1309\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[0;32m   1310\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1315\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1326\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1330\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1332\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1004\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1002\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarn_if_padding_and_no_attention_mask(input_ids, attention_mask)\n\u001b[0;32m   1003\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m-> 1004\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m \u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1005\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: cannot reshape tensor of 0 elements into shape [-1, 0] because the unspecified dimension size -1 can be any value and is ambiguous"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "# Google Sheets configuration\n",
    "SPREADSHEET_ID = '1lNZDwXKNlNkZiLWKksob55RE70e3IbSAhkR0W_pjGV4'\n",
    "SHEET_NAME = 'Sheet1'  # Adjust if necessary\n",
    "URL = f'https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/gviz/tq?tqx=out:csv&sheet={SHEET_NAME}'\n",
    "\n",
    "def fetch_data_from_sheet(url):\n",
    "    \"\"\"Fetches CSV data from the Google Sheet URL.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.content.decode('utf-8')\n",
    "    else:\n",
    "        print('Failed to fetch data.')\n",
    "        return None\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Preprocess the DataFrame to handle empty rows and group product details.\"\"\"\n",
    "    df = df.fillna('')\n",
    "    df['Product'] = df['Product'].replace('', pd.NA).ffill()\n",
    "    return df.dropna(subset=['Product'])\n",
    "\n",
    "def generate_response(prompt, model, tokenizer, max_length=100):\n",
    "    \"\"\"Generates a response from the model based on the prompt.\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_length=max_length,\n",
    "            num_return_sequences=1,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "\n",
    "    generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "def extract_keywords_from_text(text, keywords):\n",
    "    \"\"\"Extracts keywords from the given text.\"\"\"\n",
    "    text_lower = text.lower()\n",
    "    extracted_keywords = [keyword for keyword in keywords if keyword.lower() in text_lower]\n",
    "    return extracted_keywords\n",
    "\n",
    "def main():\n",
    "    # Load the trained model and tokenizer\n",
    "    model_name = 'custom_seller_bot_model'  # Directory where your trained model is saved\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "    model.eval()\n",
    "\n",
    "    # Fetch data from Google Sheets\n",
    "    csv_data = fetch_data_from_sheet(URL)\n",
    "    if not csv_data:\n",
    "        print(\"Failed to fetch data from the Google Sheet.\")\n",
    "        return\n",
    "    \n",
    "    # Convert CSV data to DataFrame\n",
    "    df = pd.read_csv(StringIO(csv_data))\n",
    "    \n",
    "    # Preprocess the data\n",
    "    df = preprocess_data(df)\n",
    "    \n",
    "    # Extract keywords from the DataFrame\n",
    "    keywords = df['Product'].dropna().unique().tolist()\n",
    "    \n",
    "    # Debug: Print keywords and DataFrame contents\n",
    "    print(f\"Keywords from DataFrame: {keywords}\")\n",
    "    print(f\"DataFrame contents:\\n{df}\")\n",
    "\n",
    "    while True:\n",
    "        # Get user input\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"Exiting...\")\n",
    "            break\n",
    "\n",
    "        # Generate response from the model\n",
    "        model_response = generate_response(user_input, model, tokenizer)\n",
    "        print(f\"Model: {model_response}\")\n",
    "\n",
    "        # Extract keywords from the model response\n",
    "        matched_keywords = extract_keywords_from_text(model_response, keywords)\n",
    "\n",
    "        # Debug: Print extracted keywords from response\n",
    "        print(f\"Keywords extracted from response: {matched_keywords}\")\n",
    "\n",
    "        if matched_keywords:\n",
    "            for keyword in matched_keywords:\n",
    "                # Check for matches in DataFrame\n",
    "                matched_rows = df[df['Product'].str.contains(keyword, case=False, na=False)]\n",
    "                if not matched_rows.empty:\n",
    "                    for _, row in matched_rows.iterrows():\n",
    "                        product_name = row['Product']\n",
    "                        brand_type = row['BrandType']\n",
    "                        price = row['Price']\n",
    "                        details = f\"We have {product_name}, {brand_type} with the price {price}\"\n",
    "                        print(details)\n",
    "                else:\n",
    "                    print(f\"Sorry, we don't have information on {keyword}.\")\n",
    "        else:\n",
    "            print(\"Sorry, I couldn't find any matching items.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords from DataFrame: ['TV', 'gas cooker', 'Fridge', 'rice cooker']\n",
      "DataFrame contents:\n",
      "        Product     BrandType     Price\n",
      "0            TV  samsung 32''  Rs.38000\n",
      "1            TV  samsung 48''  Rs.48000\n",
      "2            TV        LG 72\"  Rs.60000\n",
      "3   gas cooker          usha   Rs.15000\n",
      "4   gas cooker        samsung   Rs24000\n",
      "5        Fridge         sisil  Rs.78000\n",
      "6        Fridge       samsung  Rs.90000\n",
      "7  rice cooker        samsung   Rs.6700\n",
      "Model: i want buy a tv. Let me check the latest price for you.\n",
      "Keywords extracted from response: ['tv']\n",
      "We have TV, samsung 32'' with the price Rs.38000\n",
      "We have TV, samsung 48'' with the price Rs.48000\n",
      "We have TV, LG 72\" with the price Rs.60000\n",
      "Model: i want buy a gascooker. Let me check the latest price for you.\n",
      "Keywords extracted from response: []\n",
      "Sorry, I couldn't find any matching items.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cannot reshape tensor of 0 elements into shape [-1, 0] because the unspecified dimension size -1 can be any value and is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 115\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSorry, I couldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find any matching items.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 115\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 89\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Generate response from the model\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m model_response \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_response\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# Extract keywords from the model response\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[16], line 34\u001b[0m, in \u001b[0;36mgenerate_response\u001b[1;34m(prompt, model, tokenizer, max_length)\u001b[0m\n\u001b[0;32m     31\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 34\u001b[0m     output_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(output_ids[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m generated_text\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\transformers\\generation\\utils.py:1989\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1981\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   1982\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1983\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[0;32m   1984\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   1985\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1986\u001b[0m     )\n\u001b[0;32m   1988\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[1;32m-> 1989\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample(\n\u001b[0;32m   1990\u001b[0m         input_ids,\n\u001b[0;32m   1991\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   1992\u001b[0m         logits_warper\u001b[38;5;241m=\u001b[39mprepared_logits_warper,\n\u001b[0;32m   1993\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   1994\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   1995\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   1996\u001b[0m         streamer\u001b[38;5;241m=\u001b[39mstreamer,\n\u001b[0;32m   1997\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1998\u001b[0m     )\n\u001b[0;32m   2000\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[0;32m   2001\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2003\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   2004\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample\n\u001b[0;32m   2005\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2006\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\transformers\\generation\\utils.py:2932\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[0;32m   2929\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[0;32m   2931\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[1;32m-> 2932\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   2934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[0;32m   2935\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1315\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1307\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1309\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[0;32m   1310\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1315\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1326\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1330\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1332\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1004\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1002\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarn_if_padding_and_no_attention_mask(input_ids, attention_mask)\n\u001b[0;32m   1003\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m-> 1004\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m \u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1005\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: cannot reshape tensor of 0 elements into shape [-1, 0] because the unspecified dimension size -1 can be any value and is ambiguous"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "# Google Sheets configuration\n",
    "SPREADSHEET_ID = '1lNZDwXKNlNkZiLWKksob55RE70e3IbSAhkR0W_pjGV4'\n",
    "SHEET_NAME = 'Sheet1'  # Adjust if necessary\n",
    "URL = f'https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/gviz/tq?tqx=out:csv&sheet={SHEET_NAME}'\n",
    "\n",
    "def fetch_data_from_sheet(url):\n",
    "    \"\"\"Fetches CSV data from the Google Sheet URL.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.content.decode('utf-8')\n",
    "    else:\n",
    "        print('Failed to fetch data.')\n",
    "        return None\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Preprocess the DataFrame to handle empty rows and group product details.\"\"\"\n",
    "    df = df.fillna('')\n",
    "    df['Product'] = df['Product'].replace('', pd.NA).ffill()\n",
    "    return df.dropna(subset=['Product'])\n",
    "\n",
    "def generate_response(prompt, model, tokenizer, max_length=100):\n",
    "    \"\"\"Generates a response from the model based on the prompt.\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_length=max_length,\n",
    "            num_return_sequences=1,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "\n",
    "    generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "def extract_keywords_from_text(text, keywords):\n",
    "    \"\"\"Extracts keywords from the given text.\"\"\"\n",
    "    text_lower = text.lower()\n",
    "    extracted_keywords = [keyword.strip().lower() for keyword in keywords if keyword.strip().lower() in text_lower]\n",
    "    return extracted_keywords\n",
    "\n",
    "def main():\n",
    "    # Load the trained model and tokenizer\n",
    "    model_name = 'custom_seller_bot_model'  # Directory where your trained model is saved\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "    model.eval()\n",
    "\n",
    "    # Fetch data from Google Sheets\n",
    "    csv_data = fetch_data_from_sheet(URL)\n",
    "    if not csv_data:\n",
    "        print(\"Failed to fetch data from the Google Sheet.\")\n",
    "        return\n",
    "    \n",
    "    # Convert CSV data to DataFrame\n",
    "    df = pd.read_csv(StringIO(csv_data))\n",
    "    \n",
    "    # Preprocess the data\n",
    "    df = preprocess_data(df)\n",
    "    \n",
    "    # Extract keywords from the DataFrame\n",
    "    keywords = df['Product'].dropna().unique().tolist()\n",
    "    keywords = [keyword.strip() for keyword in keywords]  # Remove extra spaces\n",
    "\n",
    "    # Debug: Print keywords and DataFrame contents\n",
    "    print(f\"Keywords from DataFrame: {keywords}\")\n",
    "    print(f\"DataFrame contents:\\n{df}\")\n",
    "\n",
    "    while True:\n",
    "        # Get user input\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"Exiting...\")\n",
    "            break\n",
    "\n",
    "        # Generate response from the model\n",
    "        model_response = generate_response(user_input, model, tokenizer)\n",
    "        print(f\"Model: {model_response}\")\n",
    "\n",
    "        # Extract keywords from the model response\n",
    "        matched_keywords = extract_keywords_from_text(model_response, keywords)\n",
    "\n",
    "        # Debug: Print extracted keywords from response\n",
    "        print(f\"Keywords extracted from response: {matched_keywords}\")\n",
    "\n",
    "        if matched_keywords:\n",
    "            for keyword in matched_keywords:\n",
    "                # Check for matches in DataFrame\n",
    "                matched_rows = df[df['Product'].str.contains(keyword, case=False, na=False)]\n",
    "                if not matched_rows.empty:\n",
    "                    for _, row in matched_rows.iterrows():\n",
    "                        product_name = row['Product']\n",
    "                        brand_type = row['BrandType']\n",
    "                        price = row['Price']\n",
    "                        details = f\"We have {product_name}, {brand_type} with the price {price}\"\n",
    "                        print(details)\n",
    "                else:\n",
    "                    print(f\"Sorry, we don't have information on {keyword}.\")\n",
    "        else:\n",
    "            print(\"Sorry, I couldn't find any matching items.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f the issue is that keywords with spaces (like \"gas cooker\") are not being matched correctly, we need to adjust the keyword matching logic to handle multi-word keywords effectively. Here’s a solution that includes:\n",
    "\n",
    "Handling Multi-Word Keywords: Match multi-word keywords by checking if all parts of the keyword are present in the text.\n",
    "Improving Keyword Matching: Enhance the matching function to account for both exact and partial matches.\n",
    "Updated Code with Multi-Word Keyword Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords from DataFrame: ['TV', 'gas cooker', 'Fridge', 'rice cooker']\n",
      "DataFrame contents:\n",
      "        Product     BrandType     Price\n",
      "0            TV  samsung 32''  Rs.38000\n",
      "1            TV  samsung 48''  Rs.48000\n",
      "2            TV        LG 72\"  Rs.60000\n",
      "3   gas cooker          usha   Rs.15000\n",
      "4   gas cooker        samsung   Rs24000\n",
      "5        Fridge         sisil  Rs.78000\n",
      "6        Fridge       samsung  Rs.90000\n",
      "7  rice cooker        samsung   Rs.6700\n",
      "Model: i want buy a gas cooker. Let me check the latest price for you.\n",
      "Keywords extracted from response: ['gas cooker']\n",
      "We have gas cooker , usha  with the price Rs.15000\n",
      "We have gas cooker , samsung with the price Rs24000\n",
      "Model: i want buy a tv. Let me check the latest price for you.\n",
      "Keywords extracted from response: ['tv']\n",
      "We have TV, samsung 32'' with the price Rs.38000\n",
      "We have TV, samsung 48'' with the price Rs.48000\n",
      "We have TV, LG 72\" with the price Rs.60000\n",
      "Model: i want buy a rice cooker. Let me check the available rice cookers for you.\n",
      "Keywords extracted from response: ['rice cooker']\n",
      "We have rice cooker , samsung with the price Rs.6700\n",
      "Model: i ant buy a rice cooker. Let me check the latest price for you.\n",
      "Keywords extracted from response: ['rice cooker']\n",
      "We have rice cooker , samsung with the price Rs.6700\n",
      "Model: is there any offers? Sure, let me check if we have any offers on home appliances.\n",
      "Keywords extracted from response: []\n",
      "Sorry, I couldn't find any matching items.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cannot reshape tensor of 0 elements into shape [-1, 0] because the unspecified dimension size -1 can be any value and is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 121\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSorry, I couldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find any matching items.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 121\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 95\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# Generate response from the model\u001b[39;00m\n\u001b[1;32m---> 95\u001b[0m model_response \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_response\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# Extract keywords from the model response\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[17], line 34\u001b[0m, in \u001b[0;36mgenerate_response\u001b[1;34m(prompt, model, tokenizer, max_length)\u001b[0m\n\u001b[0;32m     31\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 34\u001b[0m     output_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(output_ids[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m generated_text\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\transformers\\generation\\utils.py:1989\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1981\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   1982\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1983\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[0;32m   1984\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   1985\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1986\u001b[0m     )\n\u001b[0;32m   1988\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[1;32m-> 1989\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample(\n\u001b[0;32m   1990\u001b[0m         input_ids,\n\u001b[0;32m   1991\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   1992\u001b[0m         logits_warper\u001b[38;5;241m=\u001b[39mprepared_logits_warper,\n\u001b[0;32m   1993\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   1994\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   1995\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   1996\u001b[0m         streamer\u001b[38;5;241m=\u001b[39mstreamer,\n\u001b[0;32m   1997\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1998\u001b[0m     )\n\u001b[0;32m   2000\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[0;32m   2001\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2003\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   2004\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample\n\u001b[0;32m   2005\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2006\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\transformers\\generation\\utils.py:2932\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[0;32m   2929\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[0;32m   2931\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[1;32m-> 2932\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   2934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[0;32m   2935\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1315\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1307\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1309\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[0;32m   1310\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1315\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1326\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1330\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1332\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mithi\\miniconda3\\envs\\rasa_train\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1004\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1002\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarn_if_padding_and_no_attention_mask(input_ids, attention_mask)\n\u001b[0;32m   1003\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m-> 1004\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m \u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1005\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: cannot reshape tensor of 0 elements into shape [-1, 0] because the unspecified dimension size -1 can be any value and is ambiguous"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "# Google Sheets configuration\n",
    "SPREADSHEET_ID = '1lNZDwXKNlNkZiLWKksob55RE70e3IbSAhkR0W_pjGV4'\n",
    "SHEET_NAME = 'Sheet1'  # Adjust if necessary\n",
    "URL = f'https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/gviz/tq?tqx=out:csv&sheet={SHEET_NAME}'\n",
    "\n",
    "def fetch_data_from_sheet(url):\n",
    "    \"\"\"Fetches CSV data from the Google Sheet URL.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.content.decode('utf-8')\n",
    "    else:\n",
    "        print('Failed to fetch data.')\n",
    "        return None\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Preprocess the DataFrame to handle empty rows and group product details.\"\"\"\n",
    "    df = df.fillna('')\n",
    "    df['Product'] = df['Product'].replace('', pd.NA).ffill()\n",
    "    return df.dropna(subset=['Product'])\n",
    "\n",
    "def generate_response(prompt, model, tokenizer, max_length=100):\n",
    "    \"\"\"Generates a response from the model based on the prompt.\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_length=max_length,\n",
    "            num_return_sequences=1,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "\n",
    "    generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "def extract_keywords_from_text(text, keywords):\n",
    "    \"\"\"Extracts multi-word keywords from the given text.\"\"\"\n",
    "    text_lower = text.lower()\n",
    "    extracted_keywords = []\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        keyword_lower = keyword.strip().lower()\n",
    "        if keyword_lower in text_lower:\n",
    "            extracted_keywords.append(keyword_lower)\n",
    "    \n",
    "    return extracted_keywords\n",
    "\n",
    "def main():\n",
    "    # Load the trained model and tokenizer\n",
    "    model_name = 'custom_seller_bot_model'  # Directory where your trained model is saved\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "    model.eval()\n",
    "\n",
    "    # Fetch data from Google Sheets\n",
    "    csv_data = fetch_data_from_sheet(URL)\n",
    "    if not csv_data:\n",
    "        print(\"Failed to fetch data from the Google Sheet.\")\n",
    "        return\n",
    "    \n",
    "    # Convert CSV data to DataFrame\n",
    "    df = pd.read_csv(StringIO(csv_data))\n",
    "    \n",
    "    # Preprocess the data\n",
    "    df = preprocess_data(df)\n",
    "    \n",
    "    # Extract keywords from the DataFrame\n",
    "    keywords = df['Product'].dropna().unique().tolist()\n",
    "    keywords = [keyword.strip() for keyword in keywords]  # Remove extra spaces\n",
    "\n",
    "    # Debug: Print keywords and DataFrame contents\n",
    "    print(f\"Keywords from DataFrame: {keywords}\")\n",
    "    print(f\"DataFrame contents:\\n{df}\")\n",
    "\n",
    "    while True:\n",
    "        # Get user input\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"Exiting...\")\n",
    "            break\n",
    "\n",
    "        # Generate response from the model\n",
    "        model_response = generate_response(user_input, model, tokenizer)\n",
    "        print(f\"Model: {model_response}\")\n",
    "\n",
    "        # Extract keywords from the model response\n",
    "        matched_keywords = extract_keywords_from_text(model_response, keywords)\n",
    "\n",
    "        # Debug: Print extracted keywords from response\n",
    "        print(f\"Keywords extracted from response: {matched_keywords}\")\n",
    "\n",
    "        if matched_keywords:\n",
    "            for keyword in matched_keywords:\n",
    "                # Check for matches in DataFrame\n",
    "                matched_rows = df[df['Product'].str.contains(keyword, case=False, na=False)]\n",
    "                if not matched_rows.empty:\n",
    "                    for _, row in matched_rows.iterrows():\n",
    "                        product_name = row['Product']\n",
    "                        brand_type = row['BrandType']\n",
    "                        price = row['Price']\n",
    "                        details = f\"We have {product_name}, {brand_type} with the price {price}\"\n",
    "                        print(details)\n",
    "                else:\n",
    "                    print(f\"Sorry, we don't have information on {keyword}.\")\n",
    "        else:\n",
    "            print(\"Sorry, I couldn't find any matching items.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voice interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## speaking update one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords from DataFrame: ['TV', 'gas cooker', 'Fridge', 'rice cooker', 'offers']\n",
      "DataFrame contents:\n",
      "        Product         BrandType     Price\n",
      "0            TV      samsung 32''  Rs.38000\n",
      "1            TV      samsung 48''  Rs.48000\n",
      "2            TV            LG 72\"  Rs.60000\n",
      "3   gas cooker              usha   Rs.15000\n",
      "4   gas cooker            samsung   Rs24000\n",
      "5        Fridge             sisil  Rs.78000\n",
      "6        Fridge           samsung  Rs.90000\n",
      "7  rice cooker            samsung   Rs.6700\n",
      "8        offers    samsung tv 32\"   10% off\n",
      "9        offers  usha rice cooker    5% off\n",
      "Listening...\n",
      "You: I want buy a TV\n",
      "Model: I want buy a TV. Let me check the latest price for you.\n",
      "Keywords extracted from response: ['tv']\n",
      "We have TV, samsung 32'' with the price Rs.38000\n",
      "We have TV, samsung 48'' with the price Rs.48000\n",
      "We have TV, LG 72\" with the price Rs.60000\n",
      "Listening...\n",
      "You: I won't buy a gas Google\n",
      "Model: I won't buy a gas Google. Let me check if we have any Google products on the market.\n",
      "Keywords extracted from response: []\n",
      "Sorry, I couldn't find any matching items.\n",
      "Listening...\n",
      "You: I won't buy a gas cooker\n",
      "Model: I won't buy a gas cooker. Let me check the available gas cookers for you.\n",
      "Keywords extracted from response: ['gas cooker']\n",
      "We have gas cooker , usha  with the price Rs.15000\n",
      "We have gas cooker , samsung with the price Rs24000\n",
      "Listening...\n",
      "You: exit\n",
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "from playsound import playsound\n",
    "import os\n",
    "\n",
    "# Google Sheets configuration\n",
    "SPREADSHEET_ID = '1lNZDwXKNlNkZiLWKksob55RE70e3IbSAhkR0W_pjGV4'\n",
    "SHEET_NAME = 'Sheet1'  # Adjust if necessary\n",
    "URL = f'https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/gviz/tq?tqx=out:csv&sheet={SHEET_NAME}'\n",
    "\n",
    "def fetch_data_from_sheet(url):\n",
    "    \"\"\"Fetches CSV data from the Google Sheet URL.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.content.decode('utf-8')\n",
    "    else:\n",
    "        print('Failed to fetch data.')\n",
    "        return None\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Preprocess the DataFrame to handle empty rows and group product details.\"\"\"\n",
    "    df = df.fillna('')\n",
    "    df['Product'] = df['Product'].replace('', pd.NA).ffill()\n",
    "    return df.dropna(subset=['Product'])\n",
    "\n",
    "def generate_response(prompt, model, tokenizer, max_length=100):\n",
    "    \"\"\"Generates a response from the model based on the prompt.\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_length=max_length,\n",
    "            num_return_sequences=1,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "\n",
    "    generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "def extract_keywords_from_text(text, keywords):\n",
    "    \"\"\"Extracts multi-word keywords from the given text.\"\"\"\n",
    "    text_lower = text.lower()\n",
    "    extracted_keywords = []\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        keyword_lower = keyword.strip().lower()\n",
    "        if keyword_lower in text_lower:\n",
    "            extracted_keywords.append(keyword_lower)\n",
    "    \n",
    "    return extracted_keywords\n",
    "\n",
    "def speak(text):\n",
    "    \"\"\"Convert text to speech and play it.\"\"\"\n",
    "    tts = gTTS(text=text, lang='en')\n",
    "    tts.save(\"response.mp3\")\n",
    "    playsound(\"response.mp3\")\n",
    "    os.remove(\"response.mp3\")\n",
    "\n",
    "def get_voice_input():\n",
    "    \"\"\"Capture voice input and convert it to text.\"\"\"\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening...\")\n",
    "        audio = recognizer.listen(source)\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio)\n",
    "        print(f\"You: {text}\")\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Sorry, I did not understand that.\")\n",
    "        speak(\"Sorry, I did not understand that.\")\n",
    "        return \"\"\n",
    "    except sr.RequestError:\n",
    "        print(\"Sorry, my speech service is down.\")\n",
    "        speak(\"Sorry, my speech service is down.\")\n",
    "        return \"\"\n",
    "\n",
    "def main():\n",
    "    # Load the trained model and tokenizer\n",
    "    model_name = 'custom_seller_bot_model'  # Directory where your trained model is saved\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "    model.eval()\n",
    "\n",
    "    # Fetch data from Google Sheets\n",
    "    csv_data = fetch_data_from_sheet(URL)\n",
    "    if not csv_data:\n",
    "        print(\"Failed to fetch data from the Google Sheet.\")\n",
    "        return\n",
    "    \n",
    "    # Convert CSV data to DataFrame\n",
    "    df = pd.read_csv(StringIO(csv_data))\n",
    "    \n",
    "    # Preprocess the data\n",
    "    df = preprocess_data(df)\n",
    "    \n",
    "    # Extract keywords from the DataFrame\n",
    "    keywords = df['Product'].dropna().unique().tolist()\n",
    "    keywords = [keyword.strip() for keyword in keywords]  # Remove extra spaces\n",
    "\n",
    "    # Debug: Print keywords and DataFrame contents\n",
    "    print(f\"Keywords from DataFrame: {keywords}\")\n",
    "    print(f\"DataFrame contents:\\n{df}\")\n",
    "\n",
    "    while True:\n",
    "        # Get user input\n",
    "        user_input = get_voice_input()\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"Exiting...\")\n",
    "            speak(\"Exiting.\")\n",
    "            break\n",
    "\n",
    "        if user_input.strip() == \"\":\n",
    "            continue\n",
    "\n",
    "        # Generate response from the model\n",
    "        model_response = generate_response(user_input, model, tokenizer)\n",
    "        print(f\"Model: {model_response}\")\n",
    "        speak(model_response)\n",
    "\n",
    "        # Extract keywords from the model response\n",
    "        matched_keywords = extract_keywords_from_text(model_response, keywords)\n",
    "\n",
    "        # Debug: Print extracted keywords from response\n",
    "        print(f\"Keywords extracted from response: {matched_keywords}\")\n",
    "\n",
    "        if matched_keywords:\n",
    "            for keyword in matched_keywords:\n",
    "                # Check for matches in DataFrame\n",
    "                matched_rows = df[df['Product'].str.contains(keyword, case=False, na=False)]\n",
    "                if not matched_rows.empty:\n",
    "                    for _, row in matched_rows.iterrows():\n",
    "                        product_name = row['Product']\n",
    "                        brand_type = row['BrandType']\n",
    "                        price = row['Price']\n",
    "                        details = f\"We have {product_name}, {brand_type} with the price {price}\"\n",
    "                        print(details)\n",
    "                        speak(details)\n",
    "                else:\n",
    "                    print(f\"Sorry, we don't have information on {keyword}.\")\n",
    "                    speak(f\"Sorry, we don't have information on {keyword}.\")\n",
    "        else:\n",
    "            print(\"Sorry, I couldn't find any matching items.\")\n",
    "            speak(\"Sorry, I couldn't find any matching items.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## update code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords from DataFrame: ['TV', 'gas cooker', 'Fridge', 'rice cooker', 'offers']\n",
      "DataFrame contents:\n",
      "        Product         BrandType     Price\n",
      "0            TV      samsung 32''  Rs.38000\n",
      "1            TV      samsung 48''  Rs.48000\n",
      "2            TV            LG 72\"  Rs.60000\n",
      "3   gas cooker              usha   Rs.15000\n",
      "4   gas cooker            samsung   Rs24000\n",
      "5        Fridge             sisil  Rs.78000\n",
      "6        Fridge           samsung  Rs.90000\n",
      "7  rice cooker            samsung   Rs.6700\n",
      "8        offers    samsung tv 32\"   10% off\n",
      "9        offers  usha rice cooker    5% off\n",
      "Listening...\n",
      "You: I won't buy a TV\n",
      "Model: Provide information about I won't buy a TV. Let me check if we have any news on I won't buy a TV.\n",
      "Keywords extracted from response: ['tv']\n",
      "We have TV, samsung 32'' with the price Rs.38000\n",
      "We have TV, samsung 48'' with the price Rs.48000\n",
      "We have TV, LG 72\" with the price Rs.60000\n",
      "Listening...\n",
      "Sorry, I did not understand that.\n",
      "Listening...\n",
      "You: I want buy a gas cook\n",
      "Model: Provide information about I want buy a gas cooker.\n",
      "Keywords extracted from response: ['gas cooker']\n",
      "We have gas cooker , usha  with the price Rs.15000\n",
      "We have gas cooker , samsung with the price Rs24000\n",
      "Listening...\n",
      "Sorry, I did not understand that.\n",
      "Listening...\n",
      "Sorry, I did not understand that.\n",
      "Listening...\n",
      "Sorry, I did not understand that.\n",
      "Listening...\n",
      "Sorry, I did not understand that.\n",
      "Listening...\n",
      "Sorry, I did not understand that.\n",
      "Listening...\n",
      "Sorry, I did not understand that.\n",
      "Listening...\n",
      "Sorry, I did not understand that.\n",
      "Listening...\n",
      "Sorry, I did not understand that.\n",
      "Listening...\n",
      "Sorry, I did not understand that.\n",
      "Listening...\n",
      "Sorry, I did not understand that.\n",
      "Listening...\n",
      "Sorry, I did not understand that.\n",
      "Listening...\n",
      "Sorry, I did not understand that.\n",
      "Listening...\n",
      "You: I won't buy a TV\n",
      "Model: Provide information about I won't buy a TV. Let me check if we have any deals on I won't buy a TV.\n",
      "Keywords extracted from response: ['tv']\n",
      "We have TV, samsung 32'' with the price Rs.38000\n",
      "We have TV, samsung 48'' with the price Rs.48000\n",
      "We have TV, LG 72\" with the price Rs.60000\n",
      "Listening...\n",
      "You: exit\n",
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "from playsound import playsound\n",
    "import os\n",
    "\n",
    "# Google Sheets configuration\n",
    "SPREADSHEET_ID = '1lNZDwXKNlNkZiLWKksob55RE70e3IbSAhkR0W_pjGV4'\n",
    "SHEET_NAME = 'Sheet1'  # Adjust if necessary\n",
    "URL = f'https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/gviz/tq?tqx=out:csv&sheet={SHEET_NAME}'\n",
    "\n",
    "def fetch_data_from_sheet(url):\n",
    "    \"\"\"Fetches CSV data from the Google Sheet URL.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.content.decode('utf-8')\n",
    "    else:\n",
    "        print('Failed to fetch data.')\n",
    "        return None\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Preprocess the DataFrame to handle empty rows and group product details.\"\"\"\n",
    "    df = df.fillna('')\n",
    "    df['Product'] = df['Product'].replace('', pd.NA).ffill()\n",
    "    return df.dropna(subset=['Product'])\n",
    "\n",
    "def generate_response(prompt, model, tokenizer, max_length=100):\n",
    "    \"\"\"Generates a response from the model based on the prompt.\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_length=max_length,\n",
    "            num_return_sequences=1,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "\n",
    "    generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "def extract_keywords_from_text(text, keywords):\n",
    "    \"\"\"Extracts multi-word keywords from the given text.\"\"\"\n",
    "    text_lower = text.lower()\n",
    "    extracted_keywords = []\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        keyword_lower = keyword.strip().lower()\n",
    "        if keyword_lower in text_lower:\n",
    "            extracted_keywords.append(keyword_lower)\n",
    "    \n",
    "    return extracted_keywords\n",
    "\n",
    "def speak(text):\n",
    "    \"\"\"Convert text to speech and play it.\"\"\"\n",
    "    tts = gTTS(text=text, lang='en')\n",
    "    tts.save(\"response.mp3\")\n",
    "    playsound(\"response.mp3\")\n",
    "    os.remove(\"response.mp3\")\n",
    "\n",
    "def get_voice_input():\n",
    "    \"\"\"Capture voice input and convert it to text.\"\"\"\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening...\")\n",
    "        audio = recognizer.listen(source)\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio)\n",
    "        print(f\"You: {text}\")\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Sorry, I did not understand that.\")\n",
    "        speak(\"Sorry, I did not understand that.\")\n",
    "        return \"\"\n",
    "    except sr.RequestError:\n",
    "        print(\"Sorry, my speech service is down.\")\n",
    "        speak(\"Sorry, my speech service is down.\")\n",
    "        return \"\"\n",
    "\n",
    "def main():\n",
    "    # Load the trained model and tokenizer\n",
    "    model_name = 'custom_seller_bot_model'  # Directory where your trained model is saved\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "    model.eval()\n",
    "\n",
    "    # Fetch data from Google Sheets\n",
    "    csv_data = fetch_data_from_sheet(URL)\n",
    "    if not csv_data:\n",
    "        print(\"Failed to fetch data from the Google Sheet.\")\n",
    "        return\n",
    "    \n",
    "    # Convert CSV data to DataFrame\n",
    "    df = pd.read_csv(StringIO(csv_data))\n",
    "    \n",
    "    # Preprocess the data\n",
    "    df = preprocess_data(df)\n",
    "    \n",
    "    # Extract keywords from the DataFrame\n",
    "    keywords = df['Product'].dropna().unique().tolist()\n",
    "    keywords = [keyword.strip() for keyword in keywords]  # Remove extra spaces\n",
    "\n",
    "    # Debug: Print keywords and DataFrame contents\n",
    "    print(f\"Keywords from DataFrame: {keywords}\")\n",
    "    print(f\"DataFrame contents:\\n{df}\")\n",
    "\n",
    "    while True:\n",
    "        # Get user input\n",
    "        user_input = get_voice_input()\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"Exiting...\")\n",
    "            speak(\"Exiting.\")\n",
    "            break\n",
    "\n",
    "        if user_input.strip() == \"\":\n",
    "            continue\n",
    "\n",
    "        # Generate response from the model without repeating the user's input\n",
    "        prompt = f\"Provide information about {user_input}\"\n",
    "        model_response = generate_response(prompt, model, tokenizer)\n",
    "        print(f\"Model: {model_response}\")\n",
    "        speak(model_response)\n",
    "\n",
    "        # Extract keywords from the model response\n",
    "        matched_keywords = extract_keywords_from_text(model_response, keywords)\n",
    "\n",
    "        # Debug: Print extracted keywords from response\n",
    "        print(f\"Keywords extracted from response: {matched_keywords}\")\n",
    "\n",
    "        if matched_keywords:\n",
    "            for keyword in matched_keywords:\n",
    "                # Check for matches in DataFrame\n",
    "                matched_rows = df[df['Product'].str.contains(keyword, case=False, na=False)]\n",
    "                if not matched_rows.empty:\n",
    "                    for _, row in matched_rows.iterrows():\n",
    "                        product_name = row['Product']\n",
    "                        brand_type = row['BrandType']\n",
    "                        price = row['Price']\n",
    "                        details = f\"We have {product_name}, {brand_type} with the price {price}\"\n",
    "                        print(details)\n",
    "                        speak(details)\n",
    "                else:\n",
    "                    print(f\"Sorry, we don't have information on {keyword}.\")\n",
    "                    speak(f\"Sorry, we don't have information on {keyword}.\")\n",
    "        else:\n",
    "            print(\"Sorry, I couldn't find any matching items.\")\n",
    "            speak(\"Sorry, I couldn't find any matching items.\")\n",
    "\n",
    "        speak(\"Is there any other information you want to know?\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove repeating user inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords from DataFrame: ['TV', 'gas cooker', 'Fridge', 'rice cooker', 'offers']\n",
      "DataFrame contents:\n",
      "        Product         BrandType     Price\n",
      "0            TV      samsung 32''  Rs.38000\n",
      "1            TV      samsung 48''  Rs.48000\n",
      "2            TV            LG 72\"  Rs.60000\n",
      "3   gas cooker              usha   Rs.15000\n",
      "4   gas cooker            samsung   Rs24000\n",
      "5        Fridge             sisil  Rs.78000\n",
      "6        Fridge           samsung  Rs.90000\n",
      "7  rice cooker            samsung   Rs.6700\n",
      "8        offers    samsung tv 32\"   10% off\n",
      "9        offers  usha rice cooker    5% off\n",
      "Listening...\n",
      "You: I won't buy a rice cooker\n",
      "Model response: . Let me check the available rice cookers for you.\n",
      "Keywords extracted from response: ['rice cooker']\n",
      "We have rice cooker , samsung with the price Rs.6700\n",
      "Listening...\n",
      "You: I want buy a fridge\n",
      "Model response: . Let me check the available fridges for you.\n",
      "Keywords extracted from response: ['fridge']\n",
      "We have Fridge, sisil with the price Rs.78000\n",
      "We have Fridge, samsung with the price Rs.90000\n",
      "Listening...\n",
      "You: exit\n",
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "from playsound import playsound\n",
    "import os\n",
    "\n",
    "# Google Sheets configuration\n",
    "SPREADSHEET_ID = '1lNZDwXKNlNkZiLWKksob55RE70e3IbSAhkR0W_pjGV4'\n",
    "SHEET_NAME = 'Sheet1'  # Adjust if necessary\n",
    "URL = f'https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/gviz/tq?tqx=out:csv&sheet={SHEET_NAME}'\n",
    "\n",
    "def fetch_data_from_sheet(url):\n",
    "    \"\"\"Fetches CSV data from the Google Sheet URL.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.content.decode('utf-8')\n",
    "    else:\n",
    "        print('Failed to fetch data.')\n",
    "        return None\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Preprocess the DataFrame to handle empty rows and group product details.\"\"\"\n",
    "    df = df.fillna('')\n",
    "    df['Product'] = df['Product'].replace('', pd.NA).ffill()\n",
    "    return df.dropna(subset=['Product'])\n",
    "\n",
    "def generate_response(prompt, model, tokenizer, max_length=100):\n",
    "    \"\"\"Generates a response from the model based on the prompt.\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_length=max_length,\n",
    "            num_return_sequences=1,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "\n",
    "    generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "def extract_keywords_from_text(text, keywords):\n",
    "    \"\"\"Extracts multi-word keywords from the given text.\"\"\"\n",
    "    text_lower = text.lower()\n",
    "    extracted_keywords = []\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        keyword_lower = keyword.strip().lower()\n",
    "        if keyword_lower in text_lower:\n",
    "            extracted_keywords.append(keyword_lower)\n",
    "    \n",
    "    return extracted_keywords\n",
    "\n",
    "def clean_model_response(prompt, response):\n",
    "    \"\"\"Remove the user's prompt from the model's response.\"\"\"\n",
    "    # Check if the response starts with the user's prompt and remove it\n",
    "    if response.lower().startswith(prompt.lower()):\n",
    "        response = response[len(prompt):].strip()\n",
    "    return response\n",
    "\n",
    "def format_response_for_speaking(response):\n",
    "    \"\"\"Format the response by removing trailing punctuation and excess spaces.\"\"\"\n",
    "    response = response.strip().rstrip('.')\n",
    "    return response\n",
    "\n",
    "def extract_second_part(response):\n",
    "    \"\"\"Extract the second part of the model response after removing the first part.\"\"\"\n",
    "    sentences = response.split('.')\n",
    "    if len(sentences) > 1:\n",
    "        second_part = '.'.join(sentences[1:]).strip()  # Join remaining sentences\n",
    "        return second_part\n",
    "    return \"\"\n",
    "\n",
    "def speak(text):\n",
    "    \"\"\"Convert text to speech and play it.\"\"\"\n",
    "    tts = gTTS(text=text, lang='en')\n",
    "    tts.save(\"response.mp3\")\n",
    "    playsound(\"response.mp3\")\n",
    "    os.remove(\"response.mp3\")\n",
    "\n",
    "def get_voice_input():\n",
    "    \"\"\"Capture voice input and convert it to text.\"\"\"\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening...\")\n",
    "        audio = recognizer.listen(source)\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio)\n",
    "        print(f\"You: {text}\")\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Sorry, I did not understand that.\")\n",
    "        speak(\"Sorry, I did not understand that.\")\n",
    "        return \"\"\n",
    "    except sr.RequestError:\n",
    "        print(\"Sorry, my speech service is down.\")\n",
    "        speak(\"Sorry, my speech service is down.\")\n",
    "        return \"\"\n",
    "\n",
    "def main():\n",
    "    # Load the trained model and tokenizer\n",
    "    model_name = 'custom_seller_bot_model'  # Directory where your trained model is saved\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "    model.eval()\n",
    "\n",
    "    # Fetch data from Google Sheets\n",
    "    csv_data = fetch_data_from_sheet(URL)\n",
    "    if not csv_data:\n",
    "        print(\"Failed to fetch data from the Google Sheet.\")\n",
    "        return\n",
    "    \n",
    "    # Convert CSV data to DataFrame\n",
    "    df = pd.read_csv(StringIO(csv_data))\n",
    "    \n",
    "    # Preprocess the data\n",
    "    df = preprocess_data(df)\n",
    "    \n",
    "    # Extract keywords from the DataFrame\n",
    "    keywords = df['Product'].dropna().unique().tolist()\n",
    "    keywords = [keyword.strip() for keyword in keywords]  # Remove extra spaces\n",
    "\n",
    "    # Debug: Print keywords and DataFrame contents\n",
    "    print(f\"Keywords from DataFrame: {keywords}\")\n",
    "    print(f\"DataFrame contents:\\n{df}\")\n",
    "\n",
    "    while True:\n",
    "        # Get user input\n",
    "        user_input = get_voice_input()\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"Exiting...\")\n",
    "            speak(\"Exiting.\")\n",
    "            break\n",
    "\n",
    "        if user_input.strip() == \"\":\n",
    "            continue\n",
    "\n",
    "        # Generate response from the model\n",
    "        prompt = user_input\n",
    "        model_response = generate_response(prompt, model, tokenizer)\n",
    "\n",
    "        # Clean model response\n",
    "        cleaned_response = clean_model_response(prompt, model_response)\n",
    "        \n",
    "        # Extract the second part of the model response\n",
    "        second_part = extract_second_part(cleaned_response)\n",
    "        second_part = format_response_for_speaking(second_part)\n",
    "\n",
    "        # Extract keywords from the full model response\n",
    "        matched_keywords = extract_keywords_from_text(cleaned_response, keywords)\n",
    "\n",
    "        # Debug: Print extracted keywords from response\n",
    "        print(f\"Model response: {cleaned_response}\")\n",
    "        print(f\"Keywords extracted from response: {matched_keywords}\")\n",
    "\n",
    "        # Speak the second part of the cleaned model response\n",
    "        if second_part:\n",
    "            speak(second_part)\n",
    "\n",
    "        # Check if keywords matched and provide details\n",
    "        if matched_keywords:\n",
    "            for keyword in matched_keywords:\n",
    "                # Check for matches in DataFrame\n",
    "                matched_rows = df[df['Product'].str.contains(keyword, case=False, na=False)]\n",
    "                if not matched_rows.empty:\n",
    "                    for _, row in matched_rows.iterrows():\n",
    "                        product_name = row['Product']\n",
    "                        brand_type = row['BrandType']\n",
    "                        price = row['Price']\n",
    "                        details = f\"We have {product_name}, {brand_type} with the price {price}\"\n",
    "                        print(details)\n",
    "                        speak(details)\n",
    "                else:\n",
    "                    print(f\"Sorry, we don't have information on {keyword}.\")\n",
    "                    speak(f\"Sorry, we don't have information on {keyword}.\")\n",
    "        else:\n",
    "            print(\"Sorry, I couldn't find any matching items.\")\n",
    "            speak(\"Sorry, I couldn't find any matching items.\")\n",
    "\n",
    "        speak(\"Is there any other information you want to know?\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
