{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## speak onetime if person is apper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import pyttsx3\n",
    "\n",
    "# Initialize text-to-speech engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Define paths to the model files\n",
    "prototxt_path = r'gender_pre_trained_models\\gender_deploy.prototxt'\n",
    "caffemodel_path = r'gender_pre_trained_models\\gender_net.caffemodel'\n",
    "\n",
    "# Check if files exist\n",
    "if not os.path.isfile(prototxt_path):\n",
    "    raise FileNotFoundError(f\"Cannot find the prototxt file at {prototxt_path}\")\n",
    "if not os.path.isfile(caffemodel_path):\n",
    "    raise FileNotFoundError(f\"Cannot find the caffemodel file at {caffemodel_path}\")\n",
    "\n",
    "# Load the pre-trained Caffe models for gender classification\n",
    "gender_net = cv2.dnn.readNetFromCaffe(prototxt_path, caffemodel_path)\n",
    "\n",
    "# Define the mean values for the gender model\n",
    "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "\n",
    "# Gender list\n",
    "gender_list = ['Male', 'Female']\n",
    "\n",
    "# Load the pre-trained face detection model\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Open the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize variables to keep track of detection and greeting logic\n",
    "last_detect_time = 0\n",
    "last_greet_time = 0\n",
    "greeting_interval = 2  # Interval to check if person is not available\n",
    "greeted = False\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    if len(faces) > 0:\n",
    "        last_detect_time = time.time()\n",
    "        if not greeted:\n",
    "            for (x, y, w, h) in faces:\n",
    "                # Extract the face region\n",
    "                face_img = frame[y:y+h, x:x+w].copy()\n",
    "\n",
    "                # Prepare the face image for classification\n",
    "                blob = cv2.dnn.blobFromImage(face_img, 1.0, (227, 227), MODEL_MEAN_VALUES, swapRB=False)\n",
    "                gender_net.setInput(blob)\n",
    "\n",
    "                # Perform gender classification\n",
    "                gender_preds = gender_net.forward()\n",
    "                gender = gender_list[gender_preds[0].argmax()]\n",
    "\n",
    "                # Draw a rectangle around the face and display the gender\n",
    "                label = f'{gender}'\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "                cv2.putText(frame, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "                # Say the greeting based on detected gender\n",
    "                if gender == 'Male':\n",
    "                    engine.say(\"Hello Sir\")\n",
    "                elif gender == 'Female':\n",
    "                    engine.say(\"Hello Miss\")\n",
    "                engine.runAndWait()\n",
    "                greeted = True\n",
    "    else:\n",
    "        # Check if the person has been missing for more than the greeting interval\n",
    "        if time.time() - last_detect_time >= greeting_interval:\n",
    "            greeted = False\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Gender Classification', frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## good morning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "import datetime\n",
    "import pytz\n",
    "import os\n",
    "import time\n",
    "\n",
    "def get_greeting():\n",
    "    # Define the timezone for Sri Lanka\n",
    "    sri_lanka_tz = pytz.timezone('Asia/Colombo')\n",
    "    \n",
    "    # Get the current time in Sri Lanka\n",
    "    now = datetime.datetime.now(sri_lanka_tz)\n",
    "    \n",
    "    # Determine the greeting based on the current time\n",
    "    hour = now.hour\n",
    "    if 5 <= hour < 12:\n",
    "        return \"Good morning\"\n",
    "    elif 12 <= hour < 18:\n",
    "        return \"Good afternoon\"\n",
    "    else:\n",
    "        return \"Good evening\"\n",
    "\n",
    "def speak(text):\n",
    "    # Convert text to speech\n",
    "    tts = gTTS(text=text, lang='en')\n",
    "    audio_file = 'greeting.mp3'\n",
    "    tts.save(audio_file)\n",
    "    \n",
    "    # Play the audio file\n",
    "    os.system(f\"start {audio_file}\")  # Use \"start\" for Windows, \"open\" for macOS, \"xdg-open\" for Linux\n",
    "\n",
    "def main():\n",
    "    # Define the interval for repeating greetings\n",
    "    greeting_interval = 60 * 60  # 1 hour\n",
    "    last_greeting_time = 0\n",
    "    \n",
    "    while True:\n",
    "        current_time = time.time()\n",
    "        \n",
    "        # Check if it's time to speak a new greeting\n",
    "        if current_time - last_greeting_time >= greeting_interval:\n",
    "            greeting = get_greeting()\n",
    "            speak(greeting)\n",
    "            last_greeting_time = current_time\n",
    "        \n",
    "        # Sleep for a short time to avoid high CPU usage\n",
    "        time.sleep(60)  # Check every minute\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import pyttsx3\n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "# Initialize text-to-speech engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Define paths to the model files\n",
    "prototxt_path = r'gender_pre_trained_models\\gender_deploy.prototxt'\n",
    "caffemodel_path = r'gender_pre_trained_models\\gender_net.caffemodel'\n",
    "\n",
    "# Check if files exist\n",
    "if not os.path.isfile(prototxt_path):\n",
    "    raise FileNotFoundError(f\"Cannot find the prototxt file at {prototxt_path}\")\n",
    "if not os.path.isfile(caffemodel_path):\n",
    "    raise FileNotFoundError(f\"Cannot find the caffemodel file at {caffemodel_path}\")\n",
    "\n",
    "# Load the pre-trained Caffe models for gender classification\n",
    "gender_net = cv2.dnn.readNetFromCaffe(prototxt_path, caffemodel_path)\n",
    "\n",
    "# Define the mean values for the gender model\n",
    "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "\n",
    "# Gender list\n",
    "gender_list = ['Male', 'Female']\n",
    "\n",
    "# Load the pre-trained face detection model\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Open the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize variables to keep track of detection and greeting logic\n",
    "last_detect_time = 0\n",
    "last_greet_time = 0\n",
    "greeting_interval = 2  # Interval to check if person is not available\n",
    "greeted = False\n",
    "\n",
    "def get_time_based_greeting():\n",
    "    # Define the timezone for Sri Lanka\n",
    "    sri_lanka_tz = pytz.timezone('Asia/Colombo')\n",
    "    \n",
    "    # Get the current time in Sri Lanka\n",
    "    now = datetime.datetime.now(sri_lanka_tz)\n",
    "    \n",
    "    # Determine the greeting based on the current time\n",
    "    hour = now.hour\n",
    "    if 5 <= hour < 12:\n",
    "        return \"Good morning\"\n",
    "    elif 12 <= hour < 18:\n",
    "        return \"Good afternoon\"\n",
    "    else:\n",
    "        return \"Good evening\"\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    if len(faces) > 0:\n",
    "        last_detect_time = time.time()\n",
    "        if not greeted:\n",
    "            for (x, y, w, h) in faces:\n",
    "                # Extract the face region\n",
    "                face_img = frame[y:y+h, x:x+w].copy()\n",
    "\n",
    "                # Prepare the face image for classification\n",
    "                blob = cv2.dnn.blobFromImage(face_img, 1.0, (227, 227), MODEL_MEAN_VALUES, swapRB=False)\n",
    "                gender_net.setInput(blob)\n",
    "\n",
    "                # Perform gender classification\n",
    "                gender_preds = gender_net.forward()\n",
    "                gender = gender_list[gender_preds[0].argmax()]\n",
    "\n",
    "                # Draw a rectangle around the face and display the gender\n",
    "                label = f'{gender}'\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "                cv2.putText(frame, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "                # Get the time-based greeting\n",
    "                time_based_greeting = get_time_based_greeting()\n",
    "                \n",
    "                # Say the greeting based on detected gender\n",
    "                if gender == 'Male':\n",
    "                    engine.say(f\"{time_based_greeting} Sir\")\n",
    "                elif gender == 'Female':\n",
    "                    engine.say(f\"{time_based_greeting} Miss\")\n",
    "                engine.runAndWait()\n",
    "                greeted = True\n",
    "    else:\n",
    "        # Check if the person has been missing for more than the greeting interval\n",
    "        if time.time() - last_detect_time >= greeting_interval:\n",
    "            greeted = False\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Gender Classification', frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## updated one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import pyttsx3\n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "# Initialize text-to-speech engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Define paths to the model files\n",
    "prototxt_path = r'gender_pre_trained_models\\gender_deploy.prototxt'\n",
    "caffemodel_path = r'gender_pre_trained_models\\gender_net.caffemodel'\n",
    "\n",
    "# Check if files exist\n",
    "if not os.path.isfile(prototxt_path):\n",
    "    raise FileNotFoundError(f\"Cannot find the prototxt file at {prototxt_path}\")\n",
    "if not os.path.isfile(caffemodel_path):\n",
    "    raise FileNotFoundError(f\"Cannot find the caffemodel file at {caffemodel_path}\")\n",
    "\n",
    "# Load the pre-trained Caffe models for gender classification\n",
    "gender_net = cv2.dnn.readNetFromCaffe(prototxt_path, caffemodel_path)\n",
    "\n",
    "# Define the mean values for the gender model\n",
    "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "\n",
    "# Gender list\n",
    "gender_list = ['Male', 'Female']\n",
    "\n",
    "# Load the pre-trained face detection model\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Open the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize variables to keep track of detection and greeting logic\n",
    "last_detect_time = 0\n",
    "greeting_interval = 2  # Interval to check if person is not available\n",
    "greeted = False\n",
    "\n",
    "def get_time_based_greeting():\n",
    "    # Define the timezone for Sri Lanka\n",
    "    sri_lanka_tz = pytz.timezone('Asia/Colombo')\n",
    "    \n",
    "    # Get the current time in Sri Lanka\n",
    "    now = datetime.datetime.now(sri_lanka_tz)\n",
    "    \n",
    "    # Determine the greeting based on the current time\n",
    "    hour = now.hour\n",
    "    if 5 <= hour < 12:\n",
    "        return \"Good morning\"\n",
    "    elif 12 <= hour < 18:\n",
    "        return \"Good afternoon\"\n",
    "    else:\n",
    "        return \"Good evening\"\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    if len(faces) > 0:\n",
    "        last_detect_time = time.time()\n",
    "\n",
    "        if not greeted:\n",
    "            for (x, y, w, h) in faces:\n",
    "                # Extract the face region\n",
    "                face_img = frame[y:y+h, x:x+w].copy()\n",
    "\n",
    "                # Prepare the face image for classification\n",
    "                blob = cv2.dnn.blobFromImage(face_img, 1.0, (227, 227), MODEL_MEAN_VALUES, swapRB=False)\n",
    "                gender_net.setInput(blob)\n",
    "\n",
    "                # Perform gender classification\n",
    "                gender_preds = gender_net.forward()\n",
    "                gender = gender_list[gender_preds[0].argmax()]\n",
    "\n",
    "                # Draw a rectangle around the face and display the gender\n",
    "                label = f'{gender}'\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "                cv2.putText(frame, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "                # Get the time-based greeting\n",
    "                time_based_greeting = get_time_based_greeting()\n",
    "                \n",
    "                # Say the greeting based on detected gender\n",
    "                if gender == 'Male':\n",
    "                    engine.say(f\"{time_based_greeting} Sir\")\n",
    "                elif gender == 'Female':\n",
    "                    engine.say(f\"{time_based_greeting} Miss\")\n",
    "                engine.runAndWait()\n",
    "                \n",
    "                # Set greeted to True to prevent repeated greetings\n",
    "                greeted = True\n",
    "                break  # Exit the loop after greeting\n",
    "    else:\n",
    "        # Check if the person has been missing for more than the greeting interval\n",
    "        if time.time() - last_detect_time >= greeting_interval:\n",
    "            greeted = False\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Gender Classification', frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
