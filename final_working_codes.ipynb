{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script Overview\n",
    "Imports and Configurations:\n",
    "\n",
    "Imports necessary libraries for various functionalities, such as data fetching, text-to-speech, and computer vision.\n",
    "Sets up paths and configurations for models and Google Sheets.\n",
    "Loading Models and Initial Setup:\n",
    "\n",
    "Loads the pre-trained gender classification model and face detection model.\n",
    "Initializes the webcam and the GPT-2 model for generating responses.\n",
    "Function Definitions:\n",
    "\n",
    "fetch_data_from_sheet(url): Fetches CSV data from Google Sheets.\n",
    "preprocess_data(df): Preprocesses the DataFrame by handling empty rows and grouping product details.\n",
    "generate_response(prompt, model, tokenizer, max_length=100): Generates a response from the GPT-2 model based on the given prompt.\n",
    "extract_keywords_from_text(text, keywords): Extracts keywords from the provided text.\n",
    "speak(text): Converts text to speech and plays it.\n",
    "get_voice_input(): Captures voice input and converts it to text.\n",
    "get_time_based_greeting(): Returns a time-based greeting (morning, afternoon, evening).\n",
    "Main Function Logic:\n",
    "\n",
    "Fetches data from Google Sheets and preprocesses it.\n",
    "Initializes variables to manage face detection and greeting logic.\n",
    "Continuously captures frames from the webcam, detects faces, and performs gender classification.\n",
    "If a face is detected, it greets the detected person based on their gender and asks how it can help.\n",
    "Captures voice input from the user, generates a response using the GPT-2 model, and provides relevant information based on keywords extracted from the response.\n",
    "Displays the results and handles continuous updates until the user decides to exit.\n",
    "End of Script:\n",
    "\n",
    "Releases the webcam and closes the display window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer vision code with greeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import pyttsx3\n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "# Initialize text-to-speech engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Define paths to the model files\n",
    "prototxt_path = r'gender_pre_trained_models\\gender_deploy.prototxt'\n",
    "caffemodel_path = r'gender_pre_trained_models\\gender_net.caffemodel'\n",
    "\n",
    "# Check if files exist\n",
    "if not os.path.isfile(prototxt_path):\n",
    "    raise FileNotFoundError(f\"Cannot find the prototxt file at {prototxt_path}\")\n",
    "if not os.path.isfile(caffemodel_path):\n",
    "    raise FileNotFoundError(f\"Cannot find the caffemodel file at {caffemodel_path}\")\n",
    "\n",
    "# Load the pre-trained Caffe models for gender classification\n",
    "gender_net = cv2.dnn.readNetFromCaffe(prototxt_path, caffemodel_path)\n",
    "\n",
    "# Define the mean values for the gender model\n",
    "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "\n",
    "# Gender list\n",
    "gender_list = ['Male', 'Female']\n",
    "\n",
    "# Load the pre-trained face detection model\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Open the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize variables to keep track of detection and greeting logic\n",
    "last_detect_time = 0\n",
    "greeting_interval = 2  # Interval to check if person is not available\n",
    "greeted = False\n",
    "\n",
    "def get_time_based_greeting():\n",
    "    # Define the timezone for Sri Lanka\n",
    "    sri_lanka_tz = pytz.timezone('Asia/Colombo')\n",
    "    \n",
    "    # Get the current time in Sri Lanka\n",
    "    now = datetime.datetime.now(sri_lanka_tz)\n",
    "    \n",
    "    # Determine the greeting based on the current time\n",
    "    hour = now.hour\n",
    "    if 5 <= hour < 12:\n",
    "        return \"Good morning\"\n",
    "    elif 12 <= hour < 18:\n",
    "        return \"Good afternoon\"\n",
    "    else:\n",
    "        return \"Good evening\"\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    if len(faces) > 0:\n",
    "        last_detect_time = time.time()\n",
    "\n",
    "        if not greeted:\n",
    "            for (x, y, w, h) in faces:\n",
    "                # Extract the face region\n",
    "                face_img = frame[y:y+h, x:x+w].copy()\n",
    "\n",
    "                # Prepare the face image for classification\n",
    "                blob = cv2.dnn.blobFromImage(face_img, 1.0, (227, 227), MODEL_MEAN_VALUES, swapRB=False)\n",
    "                gender_net.setInput(blob)\n",
    "\n",
    "                # Perform gender classification\n",
    "                gender_preds = gender_net.forward()\n",
    "                gender = gender_list[gender_preds[0].argmax()]\n",
    "\n",
    "                # Draw a rectangle around the face and display the gender\n",
    "                label = f'{gender}'\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "                cv2.putText(frame, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "                # Get the time-based greeting\n",
    "                time_based_greeting = get_time_based_greeting()\n",
    "                \n",
    "                # Say the greeting based on detected gender\n",
    "                if gender == 'Male':\n",
    "                    engine.say(f\"{time_based_greeting} Sir\")\n",
    "                elif gender == 'Female':\n",
    "                    engine.say(f\"{time_based_greeting} Miss\")\n",
    "                engine.runAndWait()\n",
    "                \n",
    "                # Set greeted to True to prevent repeated greetings\n",
    "                greeted = True\n",
    "                break  # Exit the loop after greeting\n",
    "    else:\n",
    "        # Check if the person has been missing for more than the greeting interval\n",
    "        if time.time() - last_detect_time >= greeting_interval:\n",
    "            greeted = False\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Gender Classification', frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat bot english as seller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "from playsound import playsound\n",
    "import os\n",
    "\n",
    "# Google Sheets configuration\n",
    "SPREADSHEET_ID = '1lNZDwXKNlNkZiLWKksob55RE70e3IbSAhkR0W_pjGV4'\n",
    "SHEET_NAME = 'Sheet1'  # Adjust if necessary\n",
    "URL = f'https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/gviz/tq?tqx=out:csv&sheet={SHEET_NAME}'\n",
    "\n",
    "def fetch_data_from_sheet(url):\n",
    "    \"\"\"Fetches CSV data from the Google Sheet URL.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.content.decode('utf-8')\n",
    "    else:\n",
    "        print('Failed to fetch data.')\n",
    "        return None\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Preprocess the DataFrame to handle empty rows and group product details.\"\"\"\n",
    "    df = df.fillna('')\n",
    "    df['Product'] = df['Product'].replace('', pd.NA).ffill()\n",
    "    return df.dropna(subset=['Product'])\n",
    "\n",
    "def generate_response(prompt, model, tokenizer, max_length=100):\n",
    "    \"\"\"Generates a response from the model based on the prompt.\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_length=max_length,\n",
    "            num_return_sequences=1,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "\n",
    "    generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "def extract_keywords_from_text(text, keywords):\n",
    "    \"\"\"Extracts multi-word keywords from the given text.\"\"\"\n",
    "    text_lower = text.lower()\n",
    "    extracted_keywords = []\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        keyword_lower = keyword.strip().lower()\n",
    "        if keyword_lower in text_lower:\n",
    "            extracted_keywords.append(keyword_lower)\n",
    "    \n",
    "    return extracted_keywords\n",
    "\n",
    "def speak(text):\n",
    "    \"\"\"Convert text to speech and play it.\"\"\"\n",
    "    tts = gTTS(text=text, lang='en')\n",
    "    tts.save(\"response.mp3\")\n",
    "    playsound(\"response.mp3\")\n",
    "    os.remove(\"response.mp3\")\n",
    "\n",
    "def get_voice_input():\n",
    "    \"\"\"Capture voice input and convert it to text.\"\"\"\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening...\")\n",
    "        audio = recognizer.listen(source)\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio)\n",
    "        print(f\"You: {text}\")\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Sorry, I did not understand that.\")\n",
    "        speak(\"Sorry, I did not understand that.\")\n",
    "        return \"\"\n",
    "    except sr.RequestError:\n",
    "        print(\"Sorry, my speech service is down.\")\n",
    "        speak(\"Sorry, my speech service is down.\")\n",
    "        return \"\"\n",
    "\n",
    "def main():\n",
    "    # Load the trained model and tokenizer\n",
    "    model_name = 'custom_seller_bot_model'  # Directory where your trained model is saved\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "    model.eval()\n",
    "\n",
    "    # Fetch data from Google Sheets\n",
    "    csv_data = fetch_data_from_sheet(URL)\n",
    "    if not csv_data:\n",
    "        print(\"Failed to fetch data from the Google Sheet.\")\n",
    "        return\n",
    "    \n",
    "    # Convert CSV data to DataFrame\n",
    "    df = pd.read_csv(StringIO(csv_data))\n",
    "    \n",
    "    # Preprocess the data\n",
    "    df = preprocess_data(df)\n",
    "    \n",
    "    # Extract keywords from the DataFrame\n",
    "    keywords = df['Product'].dropna().unique().tolist()\n",
    "    keywords = [keyword.strip() for keyword in keywords]  # Remove extra spaces\n",
    "\n",
    "    # Debug: Print keywords and DataFrame contents\n",
    "    print(f\"Keywords from DataFrame: {keywords}\")\n",
    "    print(f\"DataFrame contents:\\n{df}\")\n",
    "\n",
    "    while True:\n",
    "        # Get user input\n",
    "        user_input = get_voice_input()\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"Exiting...\")\n",
    "            speak(\"Exiting.\")\n",
    "            break\n",
    "\n",
    "        if user_input.strip() == \"\":\n",
    "            continue\n",
    "\n",
    "        # Generate response from the model\n",
    "        prompt = user_input\n",
    "        model_response = generate_response(prompt, model, tokenizer)\n",
    "        print(f\"Model response: {model_response}\")\n",
    "\n",
    "        # Split model response into sentences\n",
    "        sentences = model_response.split('.')\n",
    "        \n",
    "        if len(sentences) > 1:\n",
    "            # Extract the second sentence\n",
    "            second_sentence = sentences[1].strip()\n",
    "        else:\n",
    "            # Handle case where there is no second sentence\n",
    "            second_sentence = sentences[0].strip()\n",
    "        \n",
    "        # Extract keywords from the entire model response\n",
    "        matched_keywords = extract_keywords_from_text(model_response, keywords)\n",
    "        \n",
    "        # Speak the second sentence of the model response if it exists\n",
    "        if second_sentence:\n",
    "            speak(second_sentence)\n",
    "\n",
    "        # Handle keywords and provide pricing information\n",
    "        if matched_keywords:\n",
    "            for keyword in matched_keywords:\n",
    "                # Check for matches in DataFrame\n",
    "                matched_rows = df[df['Product'].str.contains(keyword, case=False, na=False)]\n",
    "                if not matched_rows.empty:\n",
    "                    for _, row in matched_rows.iterrows():\n",
    "                        product_name = row['Product']\n",
    "                        brand_type = row['BrandType']\n",
    "                        price = row['Price']\n",
    "                        details = f\"We have {product_name}, {brand_type} with the price {price}\"\n",
    "                        print(details)\n",
    "                        speak(details)\n",
    "                else:\n",
    "                    print(f\"Sorry, we don't have information on {keyword}.\")\n",
    "                    speak(f\"Sorry, we don't have information on {keyword}.\")\n",
    "        else:\n",
    "            if second_sentence:\n",
    "                print(\"Sorry, I couldn't find any matching items.\")\n",
    "                speak(\"Sorry, I couldn't find any matching items.\")\n",
    "\n",
    "        speak(\"Is there any other information you want to know?\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import Trainer, TrainingArguments, GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Use the correct file path\n",
    "file_path = 'prepared_customer_seller_data.csv'\n",
    "\n",
    "try:\n",
    "    # Load the CSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Combine input and response text for causal language modeling\n",
    "    df['text'] = df['input_text'] + \" \" + df['response_text']\n",
    "    \n",
    "    # Convert the DataFrame to a Dataset\n",
    "    dataset = Dataset.from_pandas(df[['text']])\n",
    "    \n",
    "    # Initialize the tokenizer and model\n",
    "    model_name = 'gpt2'  # or 'gpt2-small', 'gpt2-medium', 'gpt2-large', etc.\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "    \n",
    "    # Add a padding token if not already present\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token  # Use the end-of-sequence token as padding token\n",
    "\n",
    "    # Tokenize the combined text\n",
    "    def tokenize_function(example):\n",
    "        encodings = tokenizer(example[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "        encodings[\"labels\"] = encodings[\"input_ids\"].copy()  # Use input_ids as labels\n",
    "        return encodings\n",
    "    \n",
    "    tokenized_datasets = dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "    \n",
    "    # Prepare training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        per_device_train_batch_size=1,\n",
    "        num_train_epochs=3,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=10,\n",
    "        save_steps=500,\n",
    "        save_total_limit=2,\n",
    "        report_to=None,  # Ensure you're not using any unsupported reporting options\n",
    "    )\n",
    "    \n",
    "    # Initialize the Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets,\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "    \n",
    "    # Save the model\n",
    "    model.save_pretrained('custom_seller_bot_model')\n",
    "    tokenizer.save_pretrained('custom_seller_bot_model')\n",
    "    \n",
    "    print(\"Training complete and model saved.\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"The file at {file_path} was not found. Please check the path and try again.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
